# PepLand 全新训练架构升级方案

## 1. 战略目标
- 以全新架构“NeoPep-Encoder”取代现有 PharmHGT（`docs/项目技术调研.md:230`），重点强化对非标准氨基酸序列的表征能力，实现下游 PPI、CPP、溶解度等任务在标准与非标准数据上全面超越现有 PepLand 结果。
- 在 4×RTX 4090（96GB）计算预算内完成端到端研发与验证，确保训练吞吐与模型规模可控。

## 2. 关键约束与现状
- 预训练数据以 79.2 万条标准肽段为主，非标准样本仅约 300 条（`docs/项目技术调研.md:23`, `docs/项目技术调研.md:39`），导致现有两阶段策略对非标准数据依赖微调而非主体学习。
- 原架构基于 HGT，对长程依赖、全局上下文与多模态信息支持不足，且被多份调研认定为过时（`docs/IMPROVEMENT_STRATEGIES.md:35`）。
- 超越方案文档提出更激进路线但依赖 8×A100/5000+ GPU 小时（`docs/全面超越调研-claude.md:1819`），不符合当前算力限制，因此需重新设计在 4×4090 下可执行的整体方案。

## 3. NeoPep-Encoder 架构设计
### 3.1 总体结构
- **三分支输入编码**：
  1. **图分支**：Graph Transformer with Distance-Aware Attention（8–10 层，hidden 512），处理异构图和动态边特征；引入可学习的虚拟节点以建模全局上下文。
  2. **序列分支**：轻量化双向肽段 Transformer（12 层，hidden 384）处理氨基酸/修饰标记序列；配合位置与节段嵌入捕捉主链顺序信息。
  3. **单体属性分支**：针对非标准单体引入可学习的单体描述符矩阵（参见 4.2），采用 Set Transformer (6 层) 汇聚。
- **跨分支交互**：使用 Cross-Attention Fusion (CAF) 模块，先进行图-序列、图-单体双向注意，再通过门控混合器得到统一表征；整体头部采用 Residual Mixture-of-Experts 控制各分支权重。
- **输出层**：提供三类读出接口——图级、序列级、单体集级，方便对不同下游任务（回归/分类/序列生成）共享骨干。

### 3.2 模型规模与资源规划
- 目标总参数量：120–150M，可在混合精度下以批次 128（图分支拆分）在 4×4090 上训练。
- 训练策略：采用 ZeRO-2 + 梯度检查点以降低显存，保持每卡 24GB 占用余量；对序列分支可使用 FlashAttention 改善吞吐。

## 4. 非标准氨基酸特征策略
### 4.1 单体标准化
- 构建 HELM/Monomer 库结合，建立 `monomer_id ↔ SMILES ↔ 属性` 映射；以 `tokenizer/helm_monomer.py` 管理，区分保护基、环化、侧链修饰。
- 对所有数据执行 SMILES 归一化与原子级去重，生成 mapping table（参照 Phase 0 数据治理要求）。

### 4.2 描述符与先验
- 为每个单体构造 256 维描述符：包含 RDKit 物化特征、拓扑指数、电子参数、立体描述（chirality, ring state）。
- 使用小型图网络对单体子图进行编码，形成可更新的原子-单体嵌入。
- 引入知识蒸馏信号：从公开 QM 计算或模拟得到的偶极矩、极化率、HOMO-LUMO 间隙等作为监督。

### 4.3 多构象数据
- 采用 RDKit ETKDG 生成 ≤10 个代表性构象，计算键长/角度/质心距离矩阵，作为图分支的几何输入；不做全等变 GNN，以模块化方式纳入。

## 5. 数据与训练任务体系
### 5.1 数据扩增
- **非标准样本扩充**：
  - 从 `data/eval/nc-*` 数据集中抽取未用于训练的序列（`docs/项目技术调研.md:59`, `docs/项目技术调研.md:63`）。
  - 构造基于单体替换/变位的近邻增广，同时保留原有标签。
  - 开发基于反应模板的“修饰注入器”，扩大修饰类型覆盖。
- **外部数据导入**：整合 UniParc、PepAtlas 中非标准肽段，并借助自动化合成库（若可获取）补充具有属性标签的样本。所有外部数据需通过去重与合法性校验。

### 5.2 训练阶段
1. **Stage A：统一预训练**
   - 任务组合：
     - Graph Masking（节点/边/片段掩码）
     - Sequence Span Masking（含修饰位点预测）
     - Cross-Modal Alignment（图↔序列互预测）
     - Monomer Descriptor Reconstruction（监督单体属性）
   - Balanced Sampling：标准:非标准=3:1，确保非标准 batch 出现频率。
   - 训练预算：4×4090×48 小时，目标收敛 loss < baseline ×0.8。

2. **Stage B：非标准聚焦**
   - 可调节的 Meta-Learning：在 `further_training` 数据基础上增加 Hard Example Mining（`docs/项目技术调研.md:536`）。
   - 采用 Prototype-based Contrastive Learning：每类非标准单体建立原型向量，最小化样本与原型距离。
   - 引入属性多任务（结合 nc-binding、nc-CPP 指标）。

3. **Stage C：下游对齐与蒸馏**
   - 针对 PPI、CPP、溶解度任务，构建多任务头：分类（AUC）、回归（RMSE/Pearson）。
   - 使用 LoRA 在头部做增量微调，核心骨干保持共享。
   - 对比 baseline PepLand 输出，要求平均指标提升 ≥15%。

## 6. 工程实现与目录规划
```
neopep/
├── data/
│   ├── preprocessing/        # 单体标准化、构象生成脚本
│   ├── augmentation/         # 非标准增广
├── models/
│   ├── graph_branch.py       # Graph Transformer
│   ├── sequence_branch.py    # 肽段Transformer
│   ├── monomer_branch.py     # 单体Set Transformer
│   ├── fusion.py             # CAF模块
│   └── heads/
├── training/
│   ├── stage_a.py            # 统一预训练
│   ├── stage_b.py            # 非标准聚焦
│   ├── stage_c.py            # 下游多任务
├── evaluation/
│   ├── downstream.py         # PPI/CPP/溶解度
│   ├── robustness.py         # 非标准泛化
├── configs/
│   ├── stage_a.yaml
│   ├── stage_b.yaml
│   └── stage_c.yaml
└── docs/
    └── experiments/
```

## 7. 算力与排程
| 阶段 | GPU 配置 | 预计时长 | 关键输出 |
| --- | --- | --- | --- |
| Stage A | 4×4090, AMP + ZeRO-2 | 2 × 48h | 统一预训练 checkpoint、对比 baseline loss 下降曲线 |
| Stage B | 3×4090, prototype buffer | 36h | 非标准专用 checkpoint、原型向量库 |
| Stage C | 2×4090 | 24h | 多任务微调模型、下游评测报告 |
| 验证 | 1×4090 | 持续 | 自动化评估脚本、对比表 |

## 8. 评测与成功标准
- **PPI (c-binding/nc-binding)**：AUC 提升 ≥15%，并针对非标准子集展现 >20% 改善。
- **CPP (c-CPP/nc-CPP)**：平均 AUC ≥0.9，实现 PepLand 文档中 +5–10% 提升目标的两倍（`docs/项目技术调研.md:1344`）。
- **溶解度**：RMSE 相比 baseline 至少下降 12%，Pearson 提升 0.1 以上。
- **泛化测试**：在 OOS 拆分（Phase 0 输出）上保持 ≥10% 提升，证明非标准表征能力。

## 9. 风险与应对
| 风险 | 影响 | 缓解 |
| --- | --- | --- |
| 非标准数据仍稀缺 | 高 | 加强外部数据引入；引入对比自监督与迁移；采用虚拟样本合成 |
| 三分支模型训练不稳定 | 中 | 分阶段热启：先独立预训练各分支，再启用 CAF；逐层解冻 |
| 计算资源紧张 | 中 | 合理安排夜间全卡运行，白天用于评估/微调；Flexible batch size |
| 多任务冲突 | 低 | 使用动态损失加权与 GradNorm；必要时分离微调 |

## 10. 里程碑
1. **M1（第 4 周）**：完成数据标准化与非标准单体库，生成首版描述符。
2. **M2（第 8 周）**：三分支单独预训练完成，CAF 模块启动联合训练。
3. **M3（第 12 周）**：Stage A 完成，统一 checkpoint 与对比指标发布。
4. **M4（第 16 周）**：Stage B 完成，非标准任务集表现显著提升。
5. **M5（第 20 周）**：Stage C 完成并通过全部下游自动化评测，形成超越报告。

## 11. 后续拓展
- 若 Stage B 成果显著，可考虑引入小型等变模块或 3D 扩散生成，形成非标准肽段设计闭环。
- 输出对比论文草案与开源发布计划，为后续资金或算力扩展提供依据。

该方案以全新架构为核心，围绕非标准氨基酸的特征提取与多模态对齐展开，确保在现有算力条件下完成从数据到模型再到下游任务的全面超越。
