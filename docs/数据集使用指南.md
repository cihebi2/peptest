# PepLand 数据集使用指南

本文档详细说明 PepLand 项目中所有数据集的组织结构、内容格式、使用方法和数据量统计。

## 目录

1. [数据集总体结构](#数据集总体结构)
2. [⚠️ 重要说明：示例数据 vs 完整数据](#重要说明示例数据-vs-完整数据)
3. [预训练数据集](#预训练数据集)
4. [进一步训练数据集](#进一步训练数据集)
5. [评估数据集](#评估数据集)
6. [数据格式说明](#数据格式说明)
7. [数据处理流程](#数据处理流程)
8. [使用示例](#使用示例)

---

## 数据集总体结构

```
data/
├── pretrained/              # 第一阶段：规范氨基酸预训练数据
│   ├── train.csv           # 训练集（997条，290KB）
│   ├── valid.csv           # 验证集（997条，290KB）
│   └── test.csv            # 测试集（997条，290KB）
│
├── further_training/        # 第二阶段：非规范氨基酸进一步训练数据
│   ├── train.csv           # 训练集（68条，12KB）
│   ├── valid.csv           # 验证集（68条，12KB）
│   └── test.csv            # 测试集（68条，12KB）
│
└── eval/                    # 下游任务评估数据集
    ├── c-binding.csv       # 规范氨基酸-蛋白结合（1806条）
    ├── nc-binding.csv      # 非规范氨基酸-蛋白结合（304条）
    ├── c-CPP.txt           # 规范氨基酸-细胞穿透肽（2322条）
    ├── nc-CPP.csv          # 非规范氨基酸-细胞穿透肽（7334条）
    └── c-Sol.txt           # 规范氨基酸-溶解度（1510条）
```

**数据总量统计：**
- ⚠️ **预训练示例数据**（规范氨基酸）：2,991 条肽段（仅为示例）
- ⚠️ **进一步训练示例数据**（非规范氨基酸）：204 条肽段（仅为示例）
- ✅ **评估数据**（完整）：13,276 条肽段
- **当前仓库总计：16,471 条肽段数据**

⚠️ **重要提示：**
- 当前 `data/pretrained/` 和 `data/further_training/` 是 **示例数据**（example data）
- 完整的预训练数据集规模应该在 **数十万甚至百万级别**
- 这些示例数据仅用于测试代码流程和数据格式验证
- 如需完整数据集，请参考下方"获取完整数据集"章节

---

## ⚠️ 重要说明：示例数据 vs 完整数据

### 当前仓库的数据现状

根据 README.md 的明确说明：
> The `data` folder contains the pretraining and further training **example data**.

这意味着：

| 数据类型 | 当前状态 | 规模 | 用途 |
|---------|---------|------|------|
| `data/pretrained/` | ✅ 示例数据 | ~3,000条 | 测试代码、验证格式 |
| `data/further_training/` | ✅ 示例数据 | ~200条 | 测试代码、验证格式 |
| `data/eval/` | ✅ 完整数据 | ~13,000条 | 下游任务评估 |

### 为什么只有示例数据？

1. **数据规模限制**：完整的预训练数据集可能有数百MB甚至GB，不适合放在Git仓库
2. **版权和隐私**：一些数据可能有使用限制
3. **可复现性**：提供示例数据让用户理解格式和流程

### 完整数据集的预期规模

根据类似的肽段预训练模型（如 ProtTrans、ESM）：

| 阶段 | 预期规模 | 数据来源 |
|------|---------|---------|
| **阶段1：规范氨基酸** | 100万+ 肽段 | PeptideAtlas (数百万)、UniProt切片 |
| **阶段2：非规范氨基酸** | 5万+ 肽段 | CycPeptMPDB、合成肽库 |

**论文中的实际规模**（需要查阅论文确认）：
- 论文：https://arxiv.org/abs/2311.04419
- 查看 "Dataset" 或 "Data Collection" 章节

### 如何获取完整数据集？

#### 方法1：联系原作者

**最直接的方法**：
```
1. 访问 GitHub 仓库: https://github.com/zhangruochi/pepland
2. 查看是否有 Data Availability 说明
3. 提交 Issue 询问数据集获取方式
4. 或发邮件给论文通讯作者
```

#### 方法2：自行构建（推荐用于学习）

**步骤1：从公开数据库下载**

```python
# 示例：从 PeptideAtlas 下载数据
# 注意：这只是伪代码，实际需要使用各数据库的API

import pandas as pd
from bio import SeqIO  # Biopython

# 1. PeptideAtlas (需要注册账号)
# 下载链接: https://peptideatlas.org/builds/

# 2. UniProt 蛋白质序列切片
def generate_peptides_from_protein(protein_seq, min_len=5, max_len=50):
    """从蛋白质序列生成肽段"""
    peptides = []
    for i in range(len(protein_seq)):
        for j in range(i+min_len, min(i+max_len, len(protein_seq))+1):
            peptides.append(protein_seq[i:j])
    return peptides

# 3. 从 FASTA 文件读取
with open('uniprot_sprot.fasta', 'r') as f:
    for record in SeqIO.parse(f, 'fasta'):
        protein_seq = str(record.seq)
        peptides = generate_peptides_from_protein(protein_seq)
        # 转换为SMILES...
```

**步骤2：序列转SMILES**

```python
from rdkit import Chem

def sequence_to_smiles(sequence):
    """氨基酸序列转SMILES"""
    try:
        mol = Chem.MolFromSequence(sequence)
        if mol:
            return Chem.MolToSmiles(mol)
    except:
        return None
    return None

# 批量转换
sequences = ['ARTKQTARKSTGGKAPRKQL', 'ADLGRKITSALR', ...]
smiles_list = []
for seq in sequences:
    smi = sequence_to_smiles(seq)
    if smi:
        smiles_list.append(smi)
```

**步骤3：数据清洗和划分**

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# 去重
smiles_list = list(set(smiles_list))

# 过滤无效SMILES
from rdkit import Chem
valid_smiles = []
for smi in smiles_list:
    mol = Chem.MolFromSmiles(smi)
    if mol and mol.GetNumAtoms() > 0:
        valid_smiles.append(smi)

# 划分数据集 (90% / 5% / 5%)
train, temp = train_test_split(valid_smiles, test_size=0.1, random_state=42)
valid, test = train_test_split(temp, test_size=0.5, random_state=42)

# 保存
pd.DataFrame({'smiles': train}).to_csv('data/my_pretrained/train.csv', index=False)
pd.DataFrame({'smiles': valid}).to_csv('data/my_pretrained/valid.csv', index=False)
pd.DataFrame({'smiles': test}).to_csv('data/my_pretrained/test.csv', index=False)

print(f"训练集: {len(train)}")
print(f"验证集: {len(valid)}")
print(f"测试集: {len(test)}")
```

#### 方法3：使用公开的肽段数据集

| 数据集 | 链接 | 规模 | 格式 |
|--------|------|------|------|
| **PepBDB** | http://pepbdb.eoldham.com | ~30,000 | 序列 + SMILES |
| **CycPeptMPDB** | http://cycpeptmpdb.com | ~7,000 | SMILES |
| **SATPdb** | http://crdd.osdd.net/raghava/satpdb | ~19,000 | 序列 |

下载后统一转换为项目需要的格式。

### 使用示例数据进行开发

即使只有示例数据，你仍然可以：

1. ✅ **测试完整流程**：验证数据加载、模型训练、评估
2. ✅ **调试代码**：快速迭代，修复bug
3. ✅ **开发新功能**：添加新的数据增强、模型组件
4. ✅ **学习框架**：理解PepLand的架构和实现

**示例：使用示例数据训练**

```bash
# 1. 快速测试（1-2分钟完成）
python pretrain_masking.py \
  train.epochs=2 \
  train.batch_size=32

# 2. 观察训练曲线是否正常
# 3. 确认代码无误后，再准备大规模数据
```

---

## 预训练数据集

⚠️ **重要说明：当前为示例数据**

根据 README.md，`data/pretrained/` 目录包含的是 **example data（示例数据）**，用于：
- ✅ 测试代码流程
- ✅ 验证数据格式
- ✅ 快速原型开发
- ❌ **不是完整的预训练数据集**

### 1. 基本信息

| 项目 | 详情 |
|------|------|
| **目的** | 第一阶段预训练，学习规范氨基酸的表示 |
| **数据来源** | PepBDB、PeptideAtlas 等肽段数据库 |
| **氨基酸类型** | 20种规范氨基酸（Canonical Amino Acids） |
| **训练任务** | 自监督掩码预测（Masked Atom/Fragment Prediction） |
| **数据格式** | CSV文件，单列SMILES |

### 2. 当前示例数据量

```
train.csv:  997 条肽段（290KB）- 示例数据
valid.csv:  997 条肽段（290KB）- 示例数据
test.csv:   997 条肽段（290KB）- 示例数据
总计:       2,991 条肽段

⚠️ 这只是演示数据！完整数据集应该在数十万甚至百万级别。
```

### 3. 如何获取完整数据集

**方法1：联系原作者**
- 论文：[PepLand: arxiv.org/abs/2311.04419](https://arxiv.org/abs/2311.04419)
- GitHub：[github.com/zhangruochi/pepland](https://github.com/zhangruochi/pepland)
- 在 GitHub Issues 提问或联系作者

**方法2：自行构建数据集**

从公开数据库收集肽段序列：

| 数据库 | 网址 | 规模 | 内容 |
|--------|------|------|------|
| **PepBDB** | pepbdb.eoldham.com | ~30,000 | 生物活性肽 |
| **PeptideAtlas** | peptideatlas.org | 数百万 | 蛋白质组学鉴定肽 |
| **PepBank** | pepbank.mgh.harvard.edu | ~30,000 | 生物活性肽 |
| **UniProt** | uniprot.org | 数亿 | 蛋白质序列（可切片） |
| **CycPeptMPDB** | cycpeptmpdb.com | ~7,000 | 环肽渗透性 |
| **SATPdb** | crdd.osdd.net/raghava/satpdb | ~19,000 | 治疗性肽 |

**数据收集步骤：**
```python
# 伪代码：数据收集流程
import requests
import pandas as pd
from rdkit import Chem

# 1. 从数据库下载序列
sequences = fetch_from_database('PeptideAtlas', min_length=5, max_length=50)

# 2. 序列转SMILES
smiles_list = []
for seq in sequences:
    mol = Chem.MolFromSequence(seq)
    if mol:
        smi = Chem.MolToSmiles(mol)
        smiles_list.append(smi)

# 3. 去重和清洗
smiles_list = list(set(smiles_list))  # 去重
smiles_list = [s for s in smiles_list if is_valid_peptide(s)]  # 过滤

# 4. 保存
df = pd.DataFrame({'smiles': smiles_list})
df.to_csv('data/pretrained_large/train.csv', index=False)
```

### 3. 数据样例

```csv
smiles
C[C@H](NC(=O)[C@H](CC(=O)O)NC(=O)[C@H](CCCCN)NC(=O)[C@@H](NC(=O)[C@H](CCCCN)NC(=O)[C@H](CO)NC(=O)[C@H](CO)NC(=O)[C@@H]1CCCN1)[C@@H](C)O)C(=O)N[C@@H](CO)C(=O)O
```

**SMILES解析示例：**
- 这是一个包含 10 个氨基酸残基的肽段
- 包含：Ser(S)、Pro(P)、Lys(K)、Thr(T)、Asp(D)、Ala(A) 等规范氨基酸
- 长度范围：通常 5-50 个氨基酸

### 4. 使用场景

**训练阶段1：规范氨基酸预训练**

```yaml
# configs/pretrain_masking.yaml
train:
  dataset: pretrained          # 使用预训练数据集
  model: PharmHGT             # 从头训练模型
  batch_size: 512
  epochs: 50
  mask_rate: 0.8              # 80%的原子/片段被掩码
  mask_pharm: True            # 掩码片段
  mask_pep: 0.8               # 掩码侧链原子
```

**训练命令：**
```bash
# 修改配置文件
vim configs/pretrain_masking.yaml
# 设置 dataset: pretrained
# 设置 model: PharmHGT

# 运行训练
python pretrain_masking.py
```

---

## 进一步训练数据集

⚠️ **重要说明：当前为示例数据**

与预训练数据集一样，`data/further_training/` 也是示例数据。

### 1. 基本信息

| 项目 | 详情 |
|------|------|
| **目的** | 第二阶段微调，适应非规范氨基酸 |
| **数据来源** | CycPeptMPDB、合成肽段数据库 |
| **氨基酸类型** | 非规范氨基酸（Non-canonical Amino Acids）+ 修饰 |
| **训练任务** | 继续掩码预测，迁移学习 |
| **特殊结构** | 环肽、N/C端修饰、侧链修饰 |

### 2. 当前示例数据量

```
train.csv:  68 条肽段（12KB）- 示例数据
valid.csv:  68 条肽段（12KB）- 示例数据
test.csv:   68 条肽段（12KB）- 示例数据
总计:       204 条肽段

⚠️ 这只是演示数据！完整数据集规模未知，可能在数万级别。
```

### 3. 数据样例

```csv
smiles
CC(C)C[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[C@@H](C)NC(=O)[C@@H]2CCCN2C(=O)[C@H](Cc2ccccc2)NC(=O)[C@H](CC(C)C)N(C)C(=O)[C@@H]2CCCN2C1=O
```

**非规范氨基酸特征：**
- **N-甲基化**：`N(C)C(=O)` - N-甲基化氨基酸，增强膜通透性
- **环肽结构**：`[C@@H]1...C1=O` - 头尾相连的环状结构
- **D-氨基酸**：使用特定立体化学标记
- **非天然侧链**：苯丙氨酸衍生物、修饰亮氨酸等

### 4. 使用场景

**训练阶段2：非规范氨基酸微调**

```yaml
# configs/pretrain_masking.yaml
train:
  dataset: further_training    # 使用进一步训练数据集
  model: fine-tune             # 微调模式

inference:
  model_path: ./inference/cpkt/  # 加载第一阶段预训练权重
```

**训练命令：**
```bash
# 确保已完成第一阶段训练，生成了 cpkt/ 目录

# 修改配置文件
vim configs/pretrain_masking.yaml
# 设置 dataset: further_training
# 设置 model: fine-tune
# 设置 inference.model_path 指向第一阶段模型权重

# 运行微调
python pretrain_masking.py
```

---

## 评估数据集

### 1. 数据集概览

| 数据集 | 全称 | 任务类型 | 样本数 | 格式 | 氨基酸类型 |
|--------|------|----------|--------|------|-----------|
| **c-binding.csv** | Canonical-Binding | 蛋白质结合亲和力预测 | 1,806 | CSV | 规范 |
| **nc-binding.csv** | Non-canonical-Binding | 蛋白质结合亲和力预测 | 304 | CSV | 非规范 |
| **c-CPP.txt** | Canonical-CPP | 细胞穿透肽分类 | 2,322 | TXT | 规范 |
| **nc-CPP.csv** | Non-canonical-CPP | 细胞穿透肽分类 | 7,334 | CSV | 非规范 |
| **c-Sol.txt** | Canonical-Solubility | 溶解度预测 | 1,510 | TXT | 规范 |

**总计：13,276 条评估样本**

---

### 2. c-binding.csv - 规范氨基酸蛋白结合数据集

**任务：** 预测肽段与蛋白质的结合亲和力（回归任务）

**数据格式：**
```csv
Unnamed: 0,PDB_id,complex_type,uniprot_id,seq1,seq2,...,ligand_SMILES,affinity_measure,affinity,...
0,2P8Q,protein-peptide,Q14974 O95149,MELITILEKT...,HPRLSQYK...,...,CC(C)C[C@H](...),Kd=15.6nM,7.806875,...
```

**关键字段说明：**
- `PDB_id`: 蛋白质数据库ID（如 2P8Q）
- `complex_type`: 复合物类型（protein-peptide）
- `seq1`: 蛋白质序列（单字母缩写）
- `seq2`: 肽段序列（单字母缩写）
- `prot_SEQRES`: 蛋白质三字母序列（如 MET-GLU-LEU-...）
- `pep_SEQRES`: 肽段三字母序列（如 HIS-PRO-ARG-LEU-...）
- `ligand_SMILES`: 肽段的SMILES表示（用于模型输入）
- `affinity_measure`: 亲和力测量方式（Kd, Ki, IC50等）
- `affinity`: 亲和力数值（pKd = -log10(Kd)）
- `len_seq1`, `len_seq2`: 蛋白质和肽段长度

**样本示例：**
```
PDB_id: 2P8Q
肽段序列: HPRLSQYKSKYSSLEQSERRRRLLELQKSKRLDYVNHARR (40个氨基酸)
蛋白质: IMPORTIN-ALPHA (876个氨基酸)
亲和力: Kd=15.6nM (pKd=7.81)
SMILES: CC(C)C[C@H](NC(=O)[C@H](CCCNC(=N)N)NC(=O)...
```

**数据统计：**
- 样本数：1,806 条
- 肽段长度范围：5-50 氨基酸
- 亲和力范围：nM 到 μM 级别
- 蛋白质类型：激酶、受体、转运蛋白等

---

### 3. nc-binding.csv - 非规范氨基酸蛋白结合数据集

**与 c-binding.csv 格式相同，但肽段包含非规范氨基酸**

**数据统计：**
- 样本数：304 条
- 包含：环肽、N-甲基化、D-氨基酸、非天然侧链修饰
- 通常药物性质更好（代谢稳定性、膜通透性）

---

### 4. c-CPP.txt / nc-CPP.csv - 细胞穿透肽数据集

**任务：** 二分类，判断肽段是否能穿透细胞膜

**数据格式（TXT）：**
```
ADLGRKITSALRSLSNATIINEEVLNAMLKEVCTALLEADVNIKLVKQLRENVKSAIDLEEMASGLNKRKMIQHAVFKELVKVKVY,1
AESLSGLSLKLVKKEPRQLELTWAGSRPRNPGGNLSYELHVLNQDEEWHQMVLEPRVLLTKLQPDTTYIVRVRTLTPLGPGPFSPDHEFRTSPP,1
```

**格式说明：**
- 第1列：肽段序列（单字母缩写）
- 第2列：标签（1=CPP，0=非CPP）

**数据格式（CSV）：**
```csv
CycPeptMPDB_ID,Source,Year,Original_Name_in_Source_Literature,Structurally_Unique_ID,Same_Peptides_ID,...,SMILES,HELM,...,Permeability,PAMPA,Caco2,MDCK,RRCK,...
1,2006_Rezai_1,2006,Cyclosporine A,1,[22,932,981,...],...,C/C=C/C[C@@H](C)[C@@H](O)[C@H]1C(=O)N[C@@H](CC)...,...,-6.6,-6.6,...
```

**nc-CPP.csv 额外字段：**
- `Permeability`: 渗透性测量值（log10 Pe）
- `PAMPA`: 平行人工膜渗透性测定
- `Caco2`: 人结肠癌细胞系渗透性
- `MDCK`: 狗肾细胞系渗透性
- `HELM`: 肽段的HELM表示（标准化表示法）

**数据统计：**
- c-CPP: 2,322 条（规范氨基酸）
- nc-CPP: 7,334 条（非规范氨基酸，环肽居多）

**CPP 特征：**
- 富含碱性氨基酸（Arg, Lys）
- 正电荷密度高
- 两亲性结构
- 长度：5-30 氨基酸

---

### 5. c-Sol.txt - 溶解度数据集

**任务：** 预测肽段在水溶液中的溶解度（回归任务）

**数据格式：**
```
ADLGRKITSALRSLSNATIINEEVLNAMLKEVCTALLEADVNIKLVKQLRENVKSAIDLEEMASGLNKRKMIQHAVFKELVKVKVY,1
```

**格式说明：**
- 第1列：肽段序列
- 第2列：溶解度标签/数值

**数据统计：**
- 样本数：1,510 条
- 规范氨基酸肽段

---

## 数据格式说明

### 1. SMILES 表示法

PepLand 使用 **立体化学SMILES**（Stereochemical SMILES）表示肽段结构：

```
示例：丙氨酸-甘氨酸二肽
SMILES: C[C@H](N)C(=O)NCC(=O)O

结构解析：
- C[C@H](N):           L-丙氨酸，@表示S构型
- C(=O):               羰基（酰胺键）
- NCC(=O)O:            甘氨酸
```

**立体化学标记：**
- `@`: S-构型（L-氨基酸）
- `@@`: R-构型（D-氨基酸）
- 例：`[C@H]` = L-氨基酸，`[C@@H]` = D-氨基酸

**环状结构：**
```
环肽示例：
CC(C)C[C@@H]1NC(=O)...NC(=O)C1

- 数字 1 标记环的起点和终点
- 头尾相连形成环状结构
```

---

### 2. CSV 文件格式

**预训练和进一步训练数据集：**
```csv
smiles
CC(C)C[C@H](...省略...)C(=O)O
CC[C@H](C)[C@H](...省略...)C(=O)O
```

- 仅包含一列：`smiles`
- 每行一个肽段的SMILES表示
- 无标签（自监督学习）

**评估数据集格式因任务而异：**
- **Binding**: 多列CSV，包含序列、结构、亲和力等
- **CPP**: TXT（序列+标签）或 CSV（详细信息）
- **Solubility**: TXT（序列+标签）

---

### 3. 数据处理约定

**读取方式：**
```python
import pandas as pd

# 预训练数据
df = pd.read_csv('data/pretrained/train.csv')
smiles_list = df['smiles'].tolist()

# Binding数据
df = pd.read_csv('data/eval/c-binding.csv')
smiles = df['ligand_SMILES']
affinity = df['affinity']

# CPP数据（TXT）
df = pd.read_csv('data/eval/c-CPP.txt', header=None, names=['sequence', 'label'])
```

---

## 数据处理流程

### 1. SMILES → 异质图转换

**核心函数：** `Mol2HeteroGraph(mol, frag='258')`
**代码位置：** `model/data.py:496-632`

```python
from rdkit import Chem
from model.data import Mol2HeteroGraph

# 1. 解析SMILES
smiles = "CC(C)C[C@H](NC(=O)...)C(=O)O"
mol = Chem.MolFromSmiles(smiles)

# 2. 转换为异质图
graph = Mol2HeteroGraph(mol, frag='258')

# 图结构：
# - 节点类型: 'a' (原子), 'p' (片段/药效团)
# - 边类型: ('a','b','a') 原子-键-原子
#          ('p','r','p') 片段-反应-片段
#          ('a','j','p') 原子-连接-片段
#          ('p','j','a') 片段-连接-原子
```

**转换步骤详解：**

#### 步骤1：片段化（Fragmentation）

使用 **AdaFrag 算法**（Amiibo + BRICS）：

```python
from tokenizer.pep2fragments import get_cut_bond_idx

# 1. 识别氨基酸键和侧链
break_bonds, break_bonds_atoms = get_cut_bond_idx(mol, side_chain_cut=True)

# 2. 切割分子
if break_bonds:
    tmp = Chem.FragmentOnBonds(mol, break_bonds, addDummies=False)

# 3. 获取片段
frags_idx_lst = Chem.GetMolFrags(tmp)  # 原子索引列表
frags_mol_lst = Chem.GetMolFrags(tmp, asMols=True)  # RDKit分子对象
```

**片段类型：**
- **氨基酸主链片段**：保留肽键的骨架
- **侧链片段**：氨基酸侧链，使用BRICS进一步切割大侧链
- **示例**：
  - 亮氨酸 → 主链 + 异丁基侧链
  - 苯丙氨酸 → 主链 + 苄基侧链

#### 步骤2：提取节点特征

**原子特征（42维）：**
```python
def atom_features(atom):
    features = [
        # 原子类型 one-hot (10维): C, N, O, S, P, F, Cl, Br, I, Other
        # 度 one-hot (7维): 0-6
        # 形式电荷 one-hot (6维): -2, -1, 0, +1, +2, Other
        # 手性 one-hot (5维): Unspecified, CW, CCW, Other
        # 氢原子数 one-hot (6维): 0-5
        # 杂化类型 one-hot (6维): SP, SP2, SP3, SP3D, SP3D2, Other
        # 是否芳香 (1维): 0/1
        # 原子质量归一化 (1维): mass*0.01
    ]
    return features  # 总计42维
```

**片段特征（196维）：**
```python
def pharm_property_types_feats(mol_pharm):
    # MACCS Keys指纹 (167维)
    maccs = list(MACCSkeys.GenMACCSKeys(mol_pharm))

    # 药效团特征 (28维)
    # - 氢键供体/受体
    # - 疏水区域
    # - 正/负电荷
    # - 芳香环
    pharm = pharm_property_types_feats(mol_pharm)

    # 掩码标记 (1维)
    mask_flag = [0]

    return maccs + pharm + mask_flag  # 总计196维
```

#### 步骤3：构建异质图

```python
import dgl

# 边类型定义
edges = {
    ('a', 'b', 'a'): [],  # 原子-键-原子（化学键）
    ('p', 'r', 'p'): [],  # 片段-反应-片段（断开的键）
    ('a', 'j', 'p'): [],  # 原子-连接-片段（归属关系）
    ('p', 'j', 'a'): []   # 片段-连接-原子（反向）
}

# 1. 添加原子间的键
for bond in mol.GetBonds():
    u = bond.GetBeginAtomIdx()
    v = bond.GetEndAtomIdx()
    edges[('a', 'b', 'a')].append([u, v])
    edges[('a', 'b', 'a')].append([v, u])  # 双向

# 2. 添加片段间的反应边（断开的键）
for r in reac_idx:
    begin = r[1]  # 断键的起始原子
    end = r[2]    # 断键的终止原子
    # 连接两个原子所属的片段
    edges[('p', 'r', 'p')].append([result_ap[begin], result_ap[end]])
    edges[('p', 'r', 'p')].append([result_ap[end], result_ap[begin]])

# 3. 添加原子-片段归属边
for atom_id, pharm_id in result_ap.items():
    edges[('a', 'j', 'p')].append([atom_id, pharm_id])
    edges[('p', 'j', 'a')].append([pharm_id, atom_id])

# 4. 创建异质图
g = dgl.heterograph(edges)
```

#### 步骤4：添加边特征

**化学键特征（14维）：**
```python
def bond_features(bond):
    features = [
        0,  # 键存在标记
        bond.GetBondType() == Chem.rdchem.BondType.SINGLE,    # 单键
        bond.GetBondType() == Chem.rdchem.BondType.DOUBLE,    # 双键
        bond.GetBondType() == Chem.rdchem.BondType.TRIPLE,    # 三键
        bond.GetBondType() == Chem.rdchem.BondType.AROMATIC,  # 芳香键
        bond.GetIsConjugated(),  # 共轭
        bond.IsInRing(),         # 成环
        # 立体化学 one-hot (6维): STEREOZ, STEREOE, ...
    ]
    return features  # 总计14维
```

**最终图结构：**
```python
Graph(num_nodes={'a': 87, 'p': 12},
      num_edges={('a', 'b', 'a'): 178,
                 ('p', 'r', 'p'): 22,
                 ('a', 'j', 'p'): 87,
                 ('p', 'j', 'a'): 87},
      metagraph=[('a', 'a', 'b'), ('a', 'p', 'j'),
                 ('p', 'a', 'j'), ('p', 'p', 'r')])
```

---

### 2. 数据增强：掩码策略

**类定义：** `MaskAtom`
**代码位置：** `model/data.py:330-493`

PepLand 使用三种掩码策略进行自监督学习：

#### 策略1：随机原子掩码（Random Atom Masking）

```python
mask_atom = MaskAtom(
    num_atom_type=119,
    num_edge_type=5,
    mask_rate=0.8,      # 掩码80%的原子
    mask_edge=False,    # 不掩码边
    mask_fragment=False,
    mask_amino=False,
    mask_pep=False
)

# 应用掩码
graph = mask_atom(graph)

# 效果：
# - 随机选择 80% 的原子
# - 将其特征替换为特殊的 [MASK] 向量
# - 模型需要根据上下文预测被掩码原子的类型
```

#### 策略2：片段掩码（Fragment Masking）

```python
mask_atom = MaskAtom(
    num_atom_type=119,
    num_edge_type=5,
    mask_rate=0.8,
    mask_edge=False,
    mask_fragment=True,  # 启用片段掩码
    mask_amino=False,
    mask_pep=False
)

# 效果：
# - 掩码 80% 的片段（药效团）
# - 片段特征替换为 [MASK] 向量（196维）
# - 模型预测被掩码片段的类型（词汇表中的索引）
```

**片段词汇表：**
- 位置：`tokenizer/vocabs/Vocab_SIZE258.txt`
- 大小：258 个常见肽段片段
- 索引：0-257（258=未知片段）

#### 策略3：侧链掩码（Side Chain Masking）

```python
mask_atom = MaskAtom(
    num_atom_type=119,
    num_edge_type=5,
    mask_rate=0.8,
    mask_edge=False,
    mask_fragment=False,
    mask_amino=False,
    mask_pep=0.8  # 掩码80%的侧链原子
)

# 效果：
# - 仅掩码侧链部分的原子
# - 保留主链结构
# - 模型学习侧链与性质的关系
```

#### 策略4：氨基酸掩码（Amino Acid Masking）

```python
mask_atom = MaskAtom(
    num_atom_type=119,
    num_edge_type=5,
    mask_rate=0.8,
    mask_edge=False,
    mask_fragment=False,
    mask_amino=0.3,  # 掩码30%的氨基酸
    mask_pep=False
)

# 效果：
# - 随机选择30%的氨基酸类型
# - 掩码这些类型的所有原子
# - 模型学习氨基酸级别的表示
```

**配置方式：**
```yaml
# configs/pretrain_masking.yaml
train:
  mask_rate: 0.8       # 掩码比例
  mask_edge: False     # 是否掩码边
  mask_pharm: True     # 是否掩码片段
  mask_amino: False    # 氨基酸掩码（False或比例）
  mask_pep: 0.8        # 侧链掩码（False或比例）
```

---

### 3. 数据加载流程

**核心类：** `MolGraphSet` （IterableDataset）
**代码位置：** `model/data.py:635-706`

```python
from model.data import make_loaders, MaskAtom

# 1. 创建数据转换
transform = MaskAtom(
    num_atom_type=119,
    num_edge_type=5,
    mask_rate=0.8,
    mask_edge=False,
    mask_fragment=True,
    mask_amino=False,
    mask_pep=0.8
)

# 2. 创建数据加载器
dataloaders = make_loaders(
    cfg=cfg,
    ddp=False,
    dataset='pretrained',  # 或 'further_training'
    batch_size=512,
    num_workers=8,
    transform=transform
)

# 3. 获取训练/验证/测试数据加载器
train_loader = dataloaders['train']
valid_loader = dataloaders['valid']
test_loader = dataloaders['test']

# 4. 训练循环
for batch_graphs in train_loader:
    # batch_graphs: DGLHeteroGraph
    # - 节点特征: batch_graphs.nodes['a'].data['f']
    # - 片段特征: batch_graphs.nodes['p'].data['f']
    # - 掩码标记: batch_graphs.nodes['a'].data['mask']
    # - 标签: batch_graphs.nodes['a'].data['label']
    pass
```

**数据流：**
```
CSV文件
  ↓
读取SMILES
  ↓
RDKit解析 (Mol对象)
  ↓
片段化 (AdaFrag)
  ↓
构建异质图 (DGLHeteroGraph)
  ↓
特征提取 (原子42维, 片段196维)
  ↓
数据增强 (掩码)
  ↓
批次化 (DGL batch)
  ↓
模型输入
```

---

## 使用示例

### 1. 阶段1：规范氨基酸预训练

```bash
# 步骤1: 检查数据
head -5 data/pretrained/train.csv

# 步骤2: 修改配置
vim configs/pretrain_masking.yaml
```

```yaml
train:
  device_ids: [0]          # GPU 0
  batch_size: 512          # 批次大小
  epochs: 50               # 训练轮数
  lr: 0.001                # 学习率
  num_layer: 5             # HGT层数
  hid_dim: 300             # 隐藏维度
  mask_rate: 0.8           # 掩码率
  mask_pharm: True         # 启用片段掩码
  mask_pep: 0.8            # 侧链掩码率
  mask_amino: False        # 不使用氨基酸掩码
  dataset: pretrained      # 数据集名称
  output_model_file: cpkt  # 输出目录
  model: PharmHGT          # 模型类型（从头训练）
```

```bash
# 步骤3: 运行训练
python pretrain_masking.py

# 预期输出:
# train: 997
# Epoch [1/50] Train Loss: 3.245 Valid Loss: 2.987
# ...
# Epoch [50/50] Train Loss: 0.543 Valid Loss: 0.678
# Model saved to cpkt/

# 步骤4: 检查输出
ls -lh cpkt/
# model_0.pth
# linear_pred_atoms_0.pth
# linear_pred_pharms_0.pth
```

---

### 2. 阶段2：非规范氨基酸微调

```bash
# 步骤1: 确保第一阶段完成
ls cpkt/

# 步骤2: 修改配置
vim configs/pretrain_masking.yaml
```

```yaml
train:
  dataset: further_training  # 切换到非规范氨基酸数据
  model: fine-tune           # 微调模式

inference:
  model_path: ./cpkt/        # 加载预训练权重
```

```bash
# 步骤3: 运行微调
python pretrain_masking.py

# 预期输出:
# Loading pretrained model from ./cpkt/
# train: 68
# Epoch [1/50] Train Loss: 0.678 Valid Loss: 0.712
# ...

# 步骤4: 输出
# 微调后的模型保存到 cpkt/ （覆盖或新目录）
```

---

### 3. 评估：蛋白质结合亲和力预测

```python
# 示例代码：使用预训练模型提取特征并预测结合亲和力

import pandas as pd
from rdkit import Chem
from model.data import Mol2HeteroGraph
from model.model import PharmHGT
import torch

# 1. 加载预训练模型
model = PharmHGT(hid_dim=300, depth=5)
model.load_state_dict(torch.load('cpkt/model_0.pth'))
model.eval()

# 2. 加载binding数据
df = pd.read_csv('data/eval/c-binding.csv')

# 3. 提取特征
features = []
labels = []

for idx, row in df.iterrows():
    smiles = row['ligand_SMILES']
    affinity = row['affinity']

    # 解析并转图
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        continue

    graph = Mol2HeteroGraph(mol)

    # 提取表示
    with torch.no_grad():
        rep = model(graph)  # 肽段表示向量

    features.append(rep.numpy())
    labels.append(affinity)

features = np.array(features)
labels = np.array(labels)

# 4. 训练下游模型（回归）
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error

X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.2, random_state=42
)

regressor = RandomForestRegressor(n_estimators=100, random_state=42)
regressor.fit(X_train, y_train)

# 5. 评估
y_pred = regressor.predict(X_test)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"R2 Score: {r2:.4f}")
print(f"RMSE: {rmse:.4f}")
```

---

### 4. 评估：细胞穿透肽分类

```python
# 示例代码：CPP分类任务

import pandas as pd
from rdkit import Chem
from model.data import Mol2HeteroGraph
from model.model import PharmHGT
import torch
import numpy as np

# 1. 加载模型
model = PharmHGT(hid_dim=300, depth=5)
model.load_state_dict(torch.load('cpkt/model_0.pth'))
model.eval()

# 2. 加载CPP数据
# 注意：c-CPP.txt 格式是 sequence,label
# 需要先转换为SMILES（使用序列转SMILES工具）
df = pd.read_csv('data/eval/c-CPP.txt', header=None, names=['sequence', 'label'])

# 3. 序列转SMILES（示例）
from rdkit.Chem import AllChem

def seq_to_smiles(seq):
    # 简化版：使用RDKit的MolFromSequence
    mol = Chem.MolFromSequence(seq)
    if mol:
        return Chem.MolToSmiles(mol)
    return None

df['smiles'] = df['sequence'].apply(seq_to_smiles)
df = df.dropna(subset=['smiles'])

# 4. 提取特征
features = []
labels = []

for idx, row in df.iterrows():
    smiles = row['smiles']
    label = row['label']

    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        continue

    graph = Mol2HeteroGraph(mol)

    with torch.no_grad():
        rep = model(graph)

    features.append(rep.numpy())
    labels.append(label)

features = np.array(features)
labels = np.array(labels)

# 5. 训练分类器
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score

X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.2, random_state=42
)

classifier = RandomForestClassifier(n_estimators=100, random_state=42)
classifier.fit(X_train, y_train)

# 6. 评估
y_pred = classifier.predict(X_test)
y_proba = classifier.predict_proba(X_test)[:, 1]

acc = accuracy_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_proba)

print(f"Accuracy: {acc:.4f}")
print(f"AUC-ROC: {auc:.4f}")
```

---

### 5. 自定义数据集

如果你有自己的肽段数据，可以按以下格式准备：

```python
# 创建自定义数据集

import pandas as pd

# 1. 准备数据（单列SMILES）
smiles_list = [
    "CC(C)C[C@H](NC(=O)[C@H](CO)NC(=O)[C@@H](N)CC(C)C)C(=O)O",
    "C[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H](N)CC(=O)O)C(=O)O",
    # ... 更多SMILES
]

df = pd.DataFrame({'smiles': smiles_list})

# 2. 划分训练/验证/测试集（90%/5%/5%）
from sklearn.model_selection import train_test_split

train_df, temp_df = train_test_split(df, test_size=0.1, random_state=42)
valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)

# 3. 保存
train_df.to_csv('data/my_dataset/train.csv', index=False)
valid_df.to_csv('data/my_dataset/valid.csv', index=False)
test_df.to_csv('data/my_dataset/test.csv', index=False)

# 4. 修改配置
# vim configs/pretrain_masking.yaml
# train.dataset: my_dataset

# 5. 训练
# python pretrain_masking.py
```

---

## 数据质量与注意事项

### 1. SMILES有效性检查

```python
from rdkit import Chem

def check_smiles_validity(csv_path):
    """检查CSV文件中的SMILES是否有效"""
    df = pd.read_csv(csv_path)
    invalid = []

    for idx, row in df.iterrows():
        smiles = row['smiles']
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            invalid.append((idx, smiles))

    print(f"Total: {len(df)}, Invalid: {len(invalid)}")
    return invalid

# 检查数据
invalid = check_smiles_validity('data/pretrained/train.csv')
```

### 2. 数据统计分析

```python
def analyze_peptide_dataset(csv_path):
    """分析肽段数据集的统计特性"""
    df = pd.read_csv(csv_path)

    lengths = []
    num_atoms = []
    num_rings = []

    for smiles in df['smiles']:
        mol = Chem.MolFromSmiles(smiles)
        if mol:
            lengths.append(len(smiles))
            num_atoms.append(mol.GetNumAtoms())
            num_rings.append(Chem.GetSSSR(mol))

    print(f"Dataset: {csv_path}")
    print(f"  Samples: {len(df)}")
    print(f"  SMILES length: {np.mean(lengths):.1f} ± {np.std(lengths):.1f}")
    print(f"  Num atoms: {np.mean(num_atoms):.1f} ± {np.std(num_atoms):.1f}")
    print(f"  Num rings: {np.mean(num_rings):.1f} ± {np.std(num_rings):.1f}")

analyze_peptide_dataset('data/pretrained/train.csv')
analyze_peptide_dataset('data/further_training/train.csv')
```

### 3. 常见问题

**问题1：SMILES解析失败**
```
错误: Boost.Python.ArgumentError: Python argument types in
       Chem.MolFromSmiles(str) did not match C++ signature

解决:
- 检查SMILES格式
- 移除特殊字符
- 使用sanitize=False尝试
```

**问题2：图构建失败**
```
错误: no edge in graph

原因: 分子只有单个原子，无法构建图

解决:
- 过滤掉单原子分子
- 检查片段化算法
```

**问题3：片段词汇表不匹配**
```
警告: Warning Unfound fragments CCCC...

原因: 新片段不在词汇表中

解决:
- 使用 frag='258' 标准词汇表
- 或重新训练词汇表
```

---

## 总结

### 数据集使用流程

```
1. 预训练阶段1（规范氨基酸）
   ├── 使用: data/pretrained/
   ├── 配置: dataset='pretrained', model='PharmHGT'
   ├── 输出: cpkt/ 目录（预训练权重）
   └── 时间: ~7-8小时（单张4090）

2. 预训练阶段2（非规范氨基酸）
   ├── 使用: data/further_training/
   ├── 配置: dataset='further_training', model='fine-tune'
   ├── 加载: cpkt/ 预训练权重
   └── 时间: ~1.5-2小时（单张4090）

3. 下游任务评估
   ├── Binding: data/eval/c-binding.csv, nc-binding.csv
   ├── CPP: data/eval/c-CPP.txt, nc-CPP.csv
   ├── Solubility: data/eval/c-Sol.txt
   └── 方法: 提取特征 → 训练分类器/回归器
```

### 关键配置参数

| 参数 | 位置 | 说明 | 推荐值 |
|------|------|------|--------|
| `dataset` | train.dataset | 数据集名称 | pretrained / further_training |
| `model` | train.model | 模型类型 | PharmHGT / fine-tune |
| `batch_size` | train.batch_size | 批次大小 | 512 |
| `mask_rate` | train.mask_rate | 掩码比例 | 0.8 |
| `mask_pharm` | train.mask_pharm | 片段掩码 | True |
| `mask_pep` | train.mask_pep | 侧链掩码 | 0.8 |
| `fragment` | train.fragment | 片段词汇表 | '258' |

### 数据文件快速索引

```bash
# 预训练数据
data/pretrained/train.csv      # 997条，规范氨基酸
data/pretrained/valid.csv      # 997条
data/pretrained/test.csv       # 997条

# 微调数据
data/further_training/train.csv   # 68条，非规范氨基酸
data/further_training/valid.csv   # 68条
data/further_training/test.csv    # 68条

# 评估数据
data/eval/c-binding.csv        # 1806条，蛋白结合（规范）
data/eval/nc-binding.csv       # 304条，蛋白结合（非规范）
data/eval/c-CPP.txt            # 2322条，细胞穿透肽（规范）
data/eval/nc-CPP.csv           # 7334条，细胞穿透肽（非规范）
data/eval/c-Sol.txt            # 1510条，溶解度（规范）
```

---

**文档版本：** v1.0
**最后更新：** 2025-10-14
**维护者：** PepLand Team
