# PepLand 升级方案可行性评估

## 评估范围与约束
- 项目当前预训练数据约 79.2 万条肽段，附加非标准氨基酸数据仅约 300 条（`docs/项目技术调研.md:23`, `docs/项目技术调研.md:39`），基础模型为 5-10M 参数级的 PharmHGT（`docs/项目技术调研.md:230`）。
- 可用算力限定为 4×RTX 4090，总显存 96GB，无法复制文档中假设的 8×A100 或更大集群。
- 评估指标：预期收益、算力需求、实现复杂度、对现有代码的侵入程度，以及与数据规模是否匹配。

## PepLand 2.0 路线（`docs/升级计划-chatgpt.md`）
- **M0 数据与工程基线**（`docs/升级计划-chatgpt.md:126`）  
  建议立即执行：多策略拆分、数据治理、CI/测试体系。这一阶段主要是流程改造，算力需求低，是 4 卡环境下提升实验可靠性的最优先项。
- **M1 GraphPiece + HELM Tokenizer**（`docs/升级计划-chatgpt.md:48`, `docs/升级计划-chatgpt.md:129`, `docs/升级计划-chatgpt.md:171`）  
  有助于覆盖非标准氨基酸，工程投入中等。训练词表和改写数据管线在 4×4090 环境可控，建议在完成 M0 后启动，先实现 GraphPiece/HELM 的离线构建再逐步接入训练。
- **M2 几何等变多任务预训练**（`docs/升级计划-chatgpt.md:131`）  
  目标是 50M 样本的联合自监督与几何骨干，文档假设 8–32×A100（`docs/升级计划-chatgpt.md:141`）。在 4×4090 上难以完成同规模训练，建议缩减为：先引入 RDKit 构象的静态几何特征并验证收益，再评估是否需要 SE(3) 模型。
- **M4 条件生成与闭环优化**（`docs/升级计划-chatgpt.md:135`）  
  条件扩散与属性奖励链路需要大量预训练与评估算力；在模型尚未完成几何升级前投入风险大。建议暂缓，仅在判别式模型稳定后做小规模原型验证。

## Ultra-Think 超越方案（`docs/全面超越调研-claude.md`）
- **Graph Transformer 混合架构**（`docs/全面超越调研-claude.md:285`）  
  设计复杂，建议选取其“全局令牌+长程注意力”思路，结合较轻量的 Graphormer 实现，而非整套 PepFormer。
- **3D 几何感知网络**（`docs/全面超越调研-claude.md:400`）  
  包含多构象生成、2D-3D 融合与等变模块，且需要专门团队与 3D 数据管线。在 4×4090 下无法支撑其建议的 5000–8000 GPU 小时和 8×A100 资源（`docs/全面超越调研-claude.md:1819`）。建议拆分为：批量生成少量构象 + 在现有 GNN 上做几何特征拼接的轻量实验。
- **动态图结构 / 主动学习 / 大规模生成**（`docs/全面超越调研-claude.md:546`, `docs/全面超越调研-claude.md:928`, `docs/全面超越调研-claude.md:1377`）  
  这些方向需要长期人力与算力投入。短期内可借鉴其数据治理方法论，但完整实施需等基础模型升级和评测闭环成熟后再考虑。

## 《超越 PepLand 的全面改进策略》评估（`docs/IMPROVEMENT_STRATEGIES.md`）
- **Graphormer + Performer 主干**（`docs/IMPROVEMENT_STRATEGIES.md:136`, `docs/IMPROVEMENT_STRATEGIES.md:318`）  
  目标提升 8–12%。文档已按 4×RTX 4090 规划算力与 40–60 小时训练预算（`docs/IMPROVEMENT_STRATEGIES.md:116`, `docs/IMPROVEMENT_STRATEGIES.md:127`）。推荐先以 8 层、384 hidden 的压缩版验证收益，再逐步加深。
- **对比学习自监督**（`docs/IMPROVEMENT_STRATEGIES.md:505`）  
  计划用 2 卡即可完成（`docs/IMPROVEMENT_STRATEGIES.md:123`），对 4 卡环境友好，可与主任务交替训练。建议与掩码任务联合，重点关注温度 / 队列超参以避免不收敛风险（`docs/IMPROVEMENT_STRATEGIES.md:1624`）。
- **Adapter / LoRA 微调**（`docs/IMPROVEMENT_STRATEGIES.md:73`, `docs/IMPROVEMENT_STRATEGIES.md:1275`, `docs/IMPROVEMENT_STRATEGIES.md:1511`）  
  低成本提高下游迭代效率，适合现有算力限制。建议将 LoRA 作为下游默认选项，并保留全量微调 baseline 做对比。

## 综合优先级建议
| 时间窗口 | 推荐任务 | 说明 |
| --- | --- | --- |
| 0–4 周 | 完成数据治理、拆分、测试与训练流程基线（`docs/升级计划-chatgpt.md:126`）；梳理评测脚本 | 快速提升实验可信度，为后续大改动提供基准 |
| 1–3 月 | 引入 GraphPiece / HELM tokenizer（`docs/升级计划-chatgpt.md:48`）与 Graphormer-lite 骨干（`docs/IMPROVEMENT_STRATEGIES.md:318`）；上线对比学习支线（`docs/IMPROVEMENT_STRATEGIES.md:505`） | 在 4×4090 范围内可控，优先验证收益，逐步替换现有 HGT |
| 3–6 月 | 拓展 LoRA / Adapter 下游库（`docs/IMPROVEMENT_STRATEGIES.md:1275`）；小规模几何特征实验（`docs/全面超越调研-claude.md:400` 取其轻量部分）；评估条件生成最小原型 | 待新主干稳定后再尝试几何与生成方向，控制算力投入 |

## 暂缓或谨慎推进的事项
- 大规模几何等变预训练与 50M 样本计划（`docs/升级计划-chatgpt.md:131`）——缺乏足够算力与数据治理保障，建议先做小样本验证。
- Ultra-Think 路线中要求 8×A100 / 年度人月投入的整体计划（`docs/全面超越调研-claude.md:1819`）——与当前资源不匹配。
- 条件扩散生成器和完整闭环优化（`docs/升级计划-chatgpt.md:135`, `docs/全面超越调研-claude.md:1377`）——需在判别模型显著超越基线后再投入。

## 后续行动提示
1. 立刻整理数据拆分与 CI 需求，明确所需脚本与验收指标。
2. 规划 Graphormer-lite 与对比学习的实验矩阵，估算每轮训练时间，确保排期不超过 4×4090 的夜间预算。
3. 启动 GraphPiece / HELM 词表构建 PoC，明确与现有 tokenizer 的接口差异，准备回滚方案。
4. 为 LoRA / Adapter 设计统一微调 API，积累下游基准，对比全量微调结果。

在完成以上步骤后，可再评估是否加码几何特征或生成式模型，确保每次扩展都有明确的算力与数据支撑。
