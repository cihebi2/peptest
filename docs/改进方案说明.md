# PepLand 升级实施方案说明

## 1. 总体目标
- 在仅有 4×RTX 4090（96GB）算力预算下，使 PepLand 在主要判别式任务上实测性能提升 15–25%，同时强化工程流程与数据治理，为后续几何与生成式能力打基础。
- 确保每一阶段都有可度量的里程碑与回滚策略，避免超出现有数据规模与团队资源。

## 2. 阶段划分与时间轴
| 阶段 | 时间窗口 | 核心目标 | 主要交付 |
| --- | --- | --- | --- |
| Phase 0 | 第 0–4 周 | 数据治理 + 工程基线 | 多策略数据拆分脚本、CI/评测流程、实验配置基准 |
| Phase 1 | 第 4–12 周 | Tokenizer 升级 + 主干替换 | GraphPiece/HELM 词表、Graphormer-lite 骨干、联合掩码 + 对比预训练 | 
| Phase 2 | 第 12–20 周 | 微调效率 + 几何验证 | LoRA/Adapter 微调库、几何特征增强实验、性能回归报告 |
| Phase 3 | 第 20–26 周 | 生成式原型 + 统一评测 | 条件生成 PoC、自动化 Benchmark 看板、决策文档 |

> 注：若 Phase 1 验证未达到预期提升（≥10%），Phase 2/3 将延后 4 周并优先执行补救实验。

## 3. Phase 0：数据与工程基线
- **多策略拆分**：实现 Scaffold / 时间 / 库外 (OOS) 三套拆分脚本，记录指标；输出去重报告（Jaccard、图同构、SMILES 归一）。
- **CI/测试**：补齐数据加载、模型前向、评测脚本的单测；在 GitHub Actions 或本地 Jenkins 触发 nightly 运行；保存日志与指标至 MLflow。
- **实验配置基线**：锁定预训练与下游任务的默认超参，整理 YAML/Hydra 配置模板，建立 `experiments/` 目录。
- **资源预算**：主要占用 CPU 与 1×4090（测试），预计 200 GPU 小时内完成。
- **验收指标**：拆分脚本可重复；CI 能在 1 小时内完成全套检查；提供第一版基线性能表（含方差）。

## 4. Phase 1：Tokenizer + 主干升级
### 4.1 GraphPiece / HELM 管线
- 编写 `tokenizer/graphpiece_builder.py` 以 SentencePiece-on-Graphs 学习 5k 词表；构建版控数据集（DVC 或 git-lfs）。
- 使用 HELM 单体库统一非标准氨基酸命名，新增 `tokenizer/helm_monomer.py` 与映射表。
- 评估指标：与旧词表对比 Masked Token Acc 提升 ≥3%；下游任务在相同模型下 AUC/Pearson 增益 ≥2%。

### 4.2 Graphormer-lite Backbone
- 以 8 层、hidden 384、head 6 的 Graphormer 版本替换 HGT；保留原有多视角输入，增加全局位置编码与虚拟节点。
- 训练策略：使用混合精度 + 梯度累积 4，单次预训练 120 epoch 控制在 48 小时内（4 卡并行）。
- 评测：保持掩码任务与对比任务并行训练（SimCLR queue size 4096，温度 0.1），在验证集记录 Top-K。
- 验收：对比原 HGT 模型，综合下游指标平均提升 ≥8%，否则回退至更小规模超参并重试。

## 5. Phase 2：微调效率与几何增强
- **LoRA / Adapter 平台**：在 attention q/v 投影与 FFN 投影上挂载 rank=8 的 LoRA；提供统一接口 `finetune/lora.py`，CLI 支持快速切换；保留全量 finetune 用于对比。
- **几何特征实验**：使用 RDKit ETKDG 生成每条肽段 5 个构象，提取键长/角度/质心距离，引入到节点/边特征；不引入等变模块，先验证特征堆叠收益。
- **算力安排**：预训练保持 3 卡（夜间），LoRA 微调与几何实验在 1–2 卡轮转；预计 300 GPU 小时。
- **验收**：LoRA 微调相较全量训练速度提升 ≥3 倍且性能差距 ≤1%；几何特征带来 ≥3% 增益或明确收益不足的结论报告。

## 6. Phase 3：生成式 PoC 与统一评测
- **生成式原型**：基于现有 Graphormer 表征构建小型自回归解码器（长度 < 50），从 LoRA 微调得到的判别模型获取奖励；目标是生成满足溶解度阈值的肽段 Top-100 候选。
- **评测看板**：整合预训练、下游、生成实验指标至统一仪表板（MLflow + Streamlit/HF Space）；提供实验版本与模型校验脚本。
- **验收**：至少输出一个具备统计显著性的生成实验（与随机生成相比提升 >5%），并形成《生成评测指南》文档。

## 7. 风险与缓解
| 风险 | 等级 | 缓解措施 |
| --- | --- | --- |
| GraphPiece 词表训练不稳定 | 中 | 引入重复采样、对齐老词表回退；保留原 token pipeline |
| Graphormer-lite 收敛慢 | 中 | 使用 warmup+cos scheduler，调节层数/隐藏维度；保留 HGT 备份模型 |
| 对比学习不收敛 | 中 | 调整温度、batch 组成；必要时启用 MoCo 队列 |
| 几何特征效果有限 | 低 | 形成明确结论，作为 Phase 3 SE(3) 决策依据 |
| 生成式 PoC 耗时过长 | 高 | 限制最大训练步数，优先实现基于现有判别模型的离线 rerank |

## 8. 资源与排程概览
- **GPU 配置**：Phase 1 采用 4 卡并行；Phase 2–3 按任务拆分到 1–3 卡，保留 1 卡用于调试/评测。
- **数据需求**：Phase 0 完成后，所有数据集通过 DVC 管理并记录版本；构象数据存放于 `data/conformers/`，每周同步一次。
- **人力建议**：
  - 研究/算法：2 人（主干升级、几何实验）
  - 平台/工程：1 人（CI、数据治理、看板）
  - 数据支撑：0.5–1 人（构象生成、清洗）

## 9. 里程碑与验收清单
- **M0**：CI 绿色、拆分报告、基线指标表；PR/文档齐全。
- **M1**：GraphPiece + Graphormer-lite 模型在三大下游任务平均提升 ≥8%，提供消融实验。
- **M2**：LoRA 模块合入主分支；几何特征实验报告；下游任务性能表更新。
- **M3**：生成 PoC 结果、评测看板上线、决策文档发布。

## 10. 后续展望
- 若 Phase 2 的几何特征带来显著收益，可立项 Phase 4（SE(3) 等变模块 + 小规模构象自监督）。
- 条件生成若验证有效，后续可以扩展到扩散模型或 RL 优化，并与实验团队建立闭环。

该方案确保在现有算力限制内循序渐进地提升 PepLand 的核心能力，同时保留扩展到几何与生成式建模的清晰路径。
