# PepLand 项目技术调研报告

## 项目概述

**项目名称**: PepLand - 肽段表示学习预训练模型
**论文标题**: PepLand: a large-scale pre-trained peptide representation model for a comprehensive landscape of both canonical and non-canonical amino acids
**论文链接**: https://arxiv.org/abs/2311.04419
**项目特点**: 支持标准氨基酸和非标准氨基酸的肽段表示学习

---

## 一、数据来源

### 1.1 预训练数据

#### 第一阶段:标准氨基酸预训练数据

- **数据位置**: `data/pretrained/`
- **数据规模**:
  - 训练集: 712,397 条肽段序列
  - 验证集: 39,578 条肽段序列
  - 测试集: 39,578 条肽段序列
  - **总计**: 约 79.2万 条肽段序列
- **数据格式**: CSV格式,包含 `smiles` 列
- **数据特点**: 仅包含标准(canonical)氨基酸组成的肽段

**数据样例**:

```csv
smiles
C[C@H](NC(=O)[C@H](CC(=O)O)NC(=O)[C@H](CCCCN)NC(=O)[C@@H](NC(=O)[C@H](CCCCN)NC(=O)[C@H](CO)NC(=O)[C@H](CO)NC(=O)[C@@H]1CCCN1)[C@@H](C)O)C(=O)N[C@@H](CO)C(=O)O
CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](CC(C)C)NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](CO)NC(=O)[C@H](CCCCN)NC(=O)[C@@H](N)CCC(=O)O)C(=O)N1CCC[C@H]1C(=O)O
```

#### 第二阶段:非标准氨基酸进一步训练数据

- **数据位置**: `data/further_training/`
- **数据规模**:
  - 训练集和测试集: 各约 300条 肽段序列
- **数据特点**: 包含非标准(non-canonical)氨基酸的肽段,用于模型的进一步微调

**数据样例**:

```csv
smiles
CC(C)C[C@@H]1NC(=O)[C@H](CC(C)C)N(C)C(=O)[C@@H](C)NC(=O)[C@@H]2CCCN2C(=O)[C@H](Cc2ccccc2)NC(=O)[C@H](CC(C)C)N(C)C(=O)[C@@H]2CCCN2C1=O
CCCN1CC(=O)N(Cc2ccccc2)CC(=O)N[C@H](CC(C)C)C(=O)N2CCC[C@@H]2C(=O)N[C@H](CC(C)C)C(=O)N[C@@H](Cc2ccccc2)C1=O
```

### 1.2 下游评估数据集

**数据位置**: `data/eval/`

项目提供了多个下游任务的评估数据集:

1. **蛋白质-蛋白质相互作用 (Protein-Protein Interaction)**

   - `c-binding.csv`: 标准氨基酸肽段结合数据 (4,111,068 字节)
   - `nc-binding.csv`: 非标准氨基酸肽段结合数据 (564,876 字节)
2. **细胞穿透肽 (Cell-Penetrating Peptides, CPP)**

   - `c-CPP.txt`: 标准氨基酸CPP数据 (52,477 字节)
   - `nc-CPP.csv`: 非标准氨基酸CPP数据 (15,889,707 字节)
3. **溶解度 (Solubility)**

   - `c-Sol.txt`: 标准氨基酸肽段溶解度数据 (130,656 字节)
4. **其他评估资源**

   - `statistics.py`: 数据统计脚本
   - 多个可视化图片(物理化学性质分析、t-SNE降维可视化等)

### 1.3 数据来源说明

根据论文和代码分析,数据来源包括:

- PepAtlas数据库
- UniParc数据库
- 公开的肽段数据库
- 文献收集的实验数据

---

## 二、数据处理流程

### 2.1 分子表示转换

**核心模块**: `model/data.py` 和 `tokenizer/pep2fragments.py`

#### 2.1.1 SMILES到分子图转换

主要函数: `Mol2HeteroGraph(mol, frag='258')`

**转换流程**:

1. **分子片段化 (Fragmentation)**

   - 使用自定义的 AdaFrag 算法(Amiibo + BRICS)
   - Amiibo: 保留氨基键,切割侧链与主链连接
   - BRICS: 对大侧链进一步切割
2. **多视图异构图构建**

   - **节点类型**:

     - `a`: 原子节点 (atom nodes)
     - `p`: 片段节点 (pharmacophore/fragment nodes)
     - `junc`: 连接节点 (junction nodes)
   - **边类型**:

     - `('a', 'b', 'a')`: 原子间化学键
     - `('p', 'r', 'p')`: 片段间反应边
     - `('a', 'j', 'p')`: 原子到片段的连接边
     - `('p', 'j', 'a')`: 片段到原子的连接边
3. **特征提取**

**原子特征** (42维):

```python
def atom_features(atom):
    - 原子类型 one-hot (10维): [Br, C, N, O, F, P, S, Cl, I]
    - 度数 one-hot (6维): [0-5]
    - 形式电荷 one-hot (5维): [-1, -2, 1, 2, 0]
    - 手性标签 one-hot (4维)
    - 氢原子数 one-hot (5维): [0-4]
    - 杂化类型 one-hot (6维): [SP, SP2, SP3, SP3D, SP3D2]
    - 芳香性 (1维): [0/1]
    - 质量归一化 (1维): mass * 0.01
```

**化学键特征** (14维):

```python
def bond_features(bond):
    - 键存在性 (1维)
    - 键类型 (5维): [SINGLE, DOUBLE, TRIPLE, AROMATIC, CONJUGATED, RING]
    - 立体化学 one-hot (6维)
```

**片段特征** (196维):

```python
def pharm_property_types_feats(mol):
    - MACCS keys (167维): 分子指纹
    - 药效团性质 (27维): 氢键供体/受体、疏水性、芳香性等
    - Padding标记 (2维)
```

**片段标签**:

- 使用预定义的词汇表 (Vocab_SIZE258.txt 或 Vocab_SIZE410.txt)
- 258种片段类型 (side_chain_cut=True)
- 410种片段类型 (side_chain_cut=False)

### 2.2 数据增强与掩码策略

**核心类**: `MaskAtom`

#### 2.2.1 掩码配置参数

```python
MaskAtom(
    num_atom_type=119,    # 原子类型数量
    num_edge_type=5,       # 边类型数量
    mask_rate=0.8,         # 掩码比例
    mask_edge=False,       # 是否掩码边
    mask_fragment=True,    # 是否掩码片段
    mask_amino=False,      # 是否按氨基酸掩码
    mask_pep=0.8          # 肽段侧链掩码比例
)
```

#### 2.2.2 三种掩码策略

1. **按氨基酸掩码** (`mask_amino=0.3`)

   - 随机选择30%的氨基酸
   - 掩盖整个氨基酸的所有原子
2. **按侧链掩码** (`mask_pep=0.8`)

   - 识别肽段侧链原子
   - 随机掩盖80%的侧链原子
   - **适用于肽段特定的预训练**
3. **随机原子掩码** (`mask_rate=0.8`)

   - 随机选择80%的原子进行掩码
   - 标准的BERT式掩码策略
4. **片段掩码** (`mask_pharm=True`)

   - 与原子掩码同步进行
   - 掩盖80%的片段节点

**掩码实现**:

- 被掩码的原子/片段特征替换为特殊的掩码特征向量
- 保留掩码标签用于预训练目标

### 2.3 数据加载流程

**核心函数**: `make_loaders()`

**数据流水线**:

1. **数据集创建**

   ```python
   dataset = MolGraphSet(cfg, pd.read_csv(path), transform=MaskAtom)
   ```
2. **数据加载器配置**

   ```python
   GraphDataLoader(
       dataset,
       batch_size=512,       # 批大小
       num_workers=8,        # 并行工作进程数
       shuffle=True          # 是否打乱
   )
   ```
3. **分布式训练支持**

   - 使用 `DistributedSampler` 进行数据分片
   - 支持多GPU并行训练(DDP模式)
4. **迭代式数据生成**

   - 使用 `IterableDataset` 实现内存高效的数据流
   - 支持多进程数据加载

---

## 三、模型架构

### 3.1 核心模型: PharmHGT

**定义位置**: `model/model.py`

#### 3.1.1 模型结构

```python
class PharmHGT(nn.Module):
    def __init__(self,
                 hid_dim=300,        # 隐藏维度
                 act="ReLU",         # 激活函数
                 depth=5,            # 消息传递层数
                 atom_dim=42,        # 原子特征维度
                 bond_dim=14,        # 键特征维度
                 pharm_dim=196,      # 片段特征维度
                 reac_dim=14,        # 反应边特征维度
                 num_task=1)         # 任务数量
```

**主要组件**:

1. **特征投影层**

   ```python
   self.w_atom = nn.Linear(atom_dim, hid_dim)      # 原子特征投影
   self.w_bond = nn.Linear(bond_dim, hid_dim)      # 键特征投影
   self.w_pharm = nn.Linear(pharm_dim, hid_dim)    # 片段特征投影
   self.w_reac = nn.Linear(reac_dim, hid_dim)      # 反应边投影
   self.w_junc = nn.Linear(atom_dim + pharm_dim, hid_dim)  # 连接特征投影
   ```
2. **多视图消息传递层** (MVMP)

   ```python
   self.mp = MVMP(
       msg_func=add_attn,     # 使用注意力机制的消息函数
       hid_dim=hid_dim,
       depth=depth,           # 5层消息传递
       view='apj',            # 原子+片段+连接视图
       suffix='h',
       act=act
   )
   ```
3. **图读出层**

   ```python
   self.readout = Node_GRU(hid_dim)           # 基于GRU的图读出
   self.readout_attn = Node_GRU(hid_dim)      # 注意力增强的读出
   ```
4. **预测头** (下游任务)

   ```python
   self.out = nn.Sequential(
       nn.Linear(4 * hid_dim, hid_dim),
       self.act,
       nn.Linear(hid_dim, hid_dim),
       self.act,
       nn.Linear(hid_dim, num_task)
   )
   ```

#### 3.1.2 消息传递机制 (MVMP)

**多视图消息传递** (`class MVMP`):

1. **同构消息传递**

   - 原子-原子: `('a', 'b', 'a')`
   - 片段-片段: `('p', 'r', 'p')`
   - 使用多头注意力机制 (4个头)
2. **异构消息传递**

   - 原子-片段: `('a', 'j', 'p')`
   - 片段-原子: `('p', 'j', 'a')`
   - 通过连接节点传递信息
3. **迭代更新**

   ```python
   for i in range(depth - 1):
       # 多视图更新
       bg.multi_update_all(update_funcs, cross_reducer='sum')
       # 边更新
       for edge_type in homo_etypes:
           bg.apply_edges(self.update_edge, etype=edge_type)
   ```
4. **注意力机制**

   ```python
   class MultiHeadedAttention(nn.Module):
       def __init__(self, h=4, d_model=300):
           # 多头注意力
           # 4个注意力头,每个头维度75
   ```

#### 3.1.3 前向传播流程

```python
def forward(self, bg):
    # 1. 特征初始化
    self.init_feature(bg)

    # 2. 多视图消息传递
    self.mp(bg)

    # 3. 提取节点表示
    embed_f_a = bg.nodes['a'].data['f_h']        # 原子表示
    embed_f_p = bg.nodes['p'].data['f_h']        # 片段表示
    embed_junc_h_a = bg.nodes['a'].data['f_junc_h']  # 原子连接表示
    embed_junc_h_p = bg.nodes['p'].data['f_junc_h']  # 片段连接表示

    # 4. 多视图融合
    embed_a = torch.mean(torch.stack([embed_f_a, embed_junc_h_a], dim=1), dim=1)
    embed_p = torch.mean(torch.stack([embed_f_p, embed_junc_h_p], dim=1), dim=1)

    return embed_f_a, embed_f_p
```

### 3.2 预训练目标

#### 3.2.1 线性预测头

模型使用3个线性预测头进行预训练:

```python
linear_pred_atoms = nn.Linear(hid_dim, 119)    # 原子类型预测 (119种元素)
linear_pred_pharms = nn.Linear(hid_dim, 264)   # 片段类型预测 (264种片段)
linear_pred_bonds = nn.Linear(hid_dim, 4)      # 键类型预测 (4种键类型)
```

#### 3.2.2 预训练损失函数

**多任务联合训练**:

```python
# 1. 原子类型预测损失
pred_atom = linear_pred_atoms(atom_rep[masked_atom_indices])
loss = CrossEntropyLoss(pred_atom, true_atom_labels)

# 2. 片段类型预测损失 (如果启用)
if mask_pharm:
    pred_pharm = linear_pred_pharms(pharm_rep[masked_pharm_indices])
    loss += CrossEntropyLoss(pred_pharm, true_pharm_labels)

# 3. 键类型预测损失 (如果启用)
if mask_edge:
    pred_edge = linear_pred_bonds(edge_rep[masked_edge_indices])
    loss += CrossEntropyLoss(pred_edge, true_edge_labels)
```

**评估指标**:

- 准确率 (Accuracy): 预测正确的掩码节点/边比例
- 各任务单独统计: `acc_atom`, `acc_pharm`, `acc_edge`

### 3.3 推理模型

#### 3.3.1 特征提取器

**核心类**: `PepLandFeatureExtractor` (`model/core.py`)

```python
class PepLandFeatureExtractor(nn.Module):
    def __init__(self,
                 model_path,              # 预训练模型路径
                 pooling='avg',           # 池化方式: 'max', 'avg', 'gru'
                 freeze=True):            # 是否冻结参数

        # 加载预训练模型
        self.model = load_model(model_path)

        # 移除预测头
        for name, module in list(self.model.named_children()):
            if 'readout' in name or 'out' in name:
                delattr(self.model, name)

        # 配置池化层
        if pooling == 'max':
            pooling_layer = nn.AdaptiveMaxPool1d(output_size=1)
        elif pooling == 'avg':
            pooling_layer = nn.AdaptiveAvgPool1d(output_size=1)
        elif pooling == "gru":
            pooling_layer = Node_GRU(hid_dim=300, bidirectional=True)
```

**功能**:

1. **分子标记化** (Tokenization)

   ```python
   def tokenize(self, input_smiles: List[str]) -> List[DGLHeteroGraph]:
       # SMILES → 异构图转换
       # 内置缓存机制 (最大100,000条)
   ```
2. **原子和片段嵌入提取**

   ```python
   def extract_atom_fragment_embedding(self, input_smiles):
       atom_embeds, frag_embeds = self.model(bg)
       # atom_embeds.shape: [batch_size, max_atoms, 300]
       # frag_embeds.shape: [batch_size, max_fragments, 300]
   ```
3. **肽段嵌入提取**

   ```python
   def forward(self, input_smiles, atom_index=None):
       # 全肽段嵌入: [batch_size, 300]
       # 特定原子嵌入: [batch_size, num_atoms, 300]
   ```

#### 3.3.2 下游任务适配

**性质预测器**: `PropertyPredictor` (`model/core.py`)

```python
class PropertyPredictor(nn.Module):
    def __init__(self,
                 model_path,
                 pooling="avg",
                 hidden_dims=[256, 128],   # MLP隐藏层维度
                 mlp_dropout=0.1):

        # 冻结的特征提取器
        self.feature_model = PepLandFeatureExtractor(model_path, pooling)

        # 可训练的MLP预测头
        self.mlp = nn.Sequential(
            nn.Linear(300, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
```

---

## 四、训练策略

### 4.1 两阶段预训练策略

#### 4.1.1 第一阶段: 标准氨基酸预训练

**配置** (`configs/pretrain_masking.yaml`):

```yaml
train:
  dataset: pretrained          # 使用标准氨基酸数据
  model: PharmHGT             # 从头训练

  # 超参数
  batch_size: 512
  epochs: 50
  lr: 0.001
  decay: 0
  num_layer: 5
  hid_dim: 300

  # 掩码策略
  mask_rate: 0.8
  mask_pharm: True
  mask_pep: 0.8               # 侧链掩码
  mask_edge: False
  mask_amino: false
```

**训练流程**:

1. **数据准备**

   - 加载 712,397 条标准氨基酸肽段
   - 应用侧链掩码策略 (80%掩码率)
2. **模型训练**

   - 优化器: Adam (lr=0.001, weight_decay=0)
   - 损失函数: 交叉熵损失 (原子预测 + 片段预测)
   - 训练50个epoch
3. **验证与保存**

   - 每500步进行一次验证
   - 保存最佳模型 (基于验证集原子预测准确率)

#### 4.1.2 第二阶段: 非标准氨基酸微调

**配置**:

```yaml
train:
  dataset: further_training    # 使用非标准氨基酸数据
  model: fine-tune            # 加载第一阶段模型

inference:
  model_path: ./inference/cpkt/  # 第一阶段模型路径
```

**微调流程**:

1. **加载预训练模型**

   ```python
   if cfg.train.model == 'fine-tune':
       model, _, _ = load_model_masking(cfg.inference.model_path, device)
   ```
2. **继续训练**

   - 使用较小的非标准氨基酸数据集
   - 保持相同的掩码策略和超参数
   - 继续训练直至收敛
3. **模型保存**

   - 保存微调后的模型权重
   - 包含4个组件: 主模型 + 3个预测头

### 4.2 训练技巧与优化

#### 4.2.1 分布式训练支持

**DDP模式** (Data Distributed Parallel):

```python
if cfg.mode.ddp:
    local_rank = int(os.environ["LOCAL_RANK"])
    global_rank = int(os.environ['RANK'])
    world_size = int(os.environ['WORLD_SIZE'])

    setup_multinodes(local_rank, world_size)
    device = torch.device("cuda", local_rank)

    # 模型包装
    model_list = [
        DDP(model, device_ids=[global_rank], output_device=global_rank)
        for model in model_list
    ]
```

**特点**:

- 多GPU并行训练
- 使用 `DistributedSampler` 进行数据分片
- 梯度同步和参数更新

#### 4.2.2 实验跟踪

**MLflow集成**:

```python
mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
mlflow.set_experiment(os.environ["MLFLOW_EXPERIMENT_NAME"])

# 记录超参数
for p, v in cfg.train.items():
    mlflow.log_param(p, v)

# 记录指标
mlflow.log_metric("train/loss", loss, step=global_step)
mlflow.log_metric("train/acc_atom", acc_atom, step=global_step)

# 保存模型
mlflow.pytorch.save_model(model, path=model_path)
```

#### 4.2.3 模型检查点

**保存策略**:

```python
# 基于验证集性能保存最佳模型
if metrics['valid_acc_atom'] >= self.best_metric:
    self.best_metric = metrics['valid_acc_atom']

    # 保存所有组件
    mlflow.pytorch.save_model(model, path='model/')
    mlflow.pytorch.save_model(linear_pred_atoms, path='linear_pred_atoms/')
    mlflow.pytorch.save_model(linear_pred_pharms, path='linear_pred_pharms/')
    mlflow.pytorch.save_model(linear_pred_bonds, path='linear_pred_bonds/')
```

**检查点包含**:

1. 主模型 (PharmHGT)
2. 原子预测头
3. 片段预测头
4. 键预测头

### 4.3 训练监控

#### 4.3.1 日志记录

**每5步记录一次**:

```python
if (global_train_step + 1) % 5 == 0:
    Logger.info("train | epoch: {} step: {} | loss: {:.4f}".format(
        epoch, global_train_step, loss))
```

#### 4.3.2 评估指标

**训练指标**:

- `train/loss`: 总损失
- `train/acc_atom`: 原子预测准确率
- `train/acc_pharm`: 片段预测准确率
- `train/acc_edge`: 键预测准确率

**验证指标**:

- `valid/loss`, `valid/acc_atom`, `valid/acc_pharm`, `valid/acc_edge`

**测试指标**:

- `test/loss`, `test/acc_atom`, `test/acc_pharm`, `test/acc_edge`

---

## 五、评价方式

### 5.1 预训练评估

#### 5.1.1 自监督任务评估

**评估指标** (`trainer.py:evaluate()`):

1. **原子类型预测准确率**

   ```python
   pred_atom = linear_pred_atoms(atom_rep[masked_indices])
   acc_atom = compute_accuracy(pred_atom, true_labels)
   ```

   - 衡量模型对原子类型的预测能力
   - 目标: >85% 准确率
2. **片段类型预测准确率**

   ```python
   pred_pharm = linear_pred_pharms(pharm_rep[masked_indices])
   acc_pharm = compute_accuracy(pred_pharm, true_labels)
   ```

   - 衡量模型对片段结构的理解
   - 目标: >75% 准确率
3. **键类型预测准确率**

   ```python
   pred_edge = linear_pred_bonds(edge_rep[masked_indices])
   acc_edge = compute_accuracy(pred_edge, true_labels)
   ```

   - 衡量模型对化学键的认知
   - 目标: >80% 准确率

#### 5.1.2 评估流程

```python
def evaluate(self, split):
    model.eval()

    # 遍历数据集
    for batch in tqdm(dataloaders[split]):
        atom_rep, pharm_rep = model(batch)

        # 计算各任务损失和准确率
        loss = 0
        loss += criterion(pred_atom, true_atom_label)
        loss += criterion(pred_pharm, true_pharm_label)
        loss += criterion(pred_edge, true_edge_label)

        # 累积指标
        acc_atom_accum += compute_accuracy(pred_atom, true_atom_label)
        acc_pharm_accum += compute_accuracy(pred_pharm, true_pharm_label)
        acc_edge_accum += compute_accuracy(pred_edge, true_edge_label)

    # 返回平均指标
    return {
        f'{split}_loss': loss_accum / num_batches,
        f'{split}_acc_atom': acc_atom_accum / num_batches,
        f'{split}_acc_pharm': acc_pharm_accum / num_batches,
        f'{split}_acc_edge': acc_edge_accum / num_batches
    }
```

### 5.2 下游任务评估

#### 5.2.1 评估指标 (`utils/metrics.py`)

**1. 分类任务指标** (`MulticlassMetrics`):

```python
class MulticlassMetrics:
    def __call__(self, pred, true):
        # 精确率
        precision_score = precision_score(true, pred, average="macro")

        # 召回率
        recall_score = recall_score(true, pred, average="macro")

        # AUC分数
        auc_score = roc_auc_score(true, pred, average="macro")

        # 分类报告
        report = classification_report(true, pred)

        return {
            "precision_score": precision_score,
            "recall_score": recall_score,
            "auc_score": auc_score,
            "classification_report": report
        }
```

**2. 回归任务指标** (`AffinityMetrics`):

```python
class AffinityMetrics:
    def __init__(self, topK):
        self.topK = topK

    def __call__(self, pred, true):
        # 均方误差
        mse = (np.square(pred - true)).mean()

        # 皮尔逊相关系数
        pearson_corr = pearsonr(pred, true)[0]

        # 斯皮尔曼相关系数
        spearman_corr = spearmanr(pred, true)[0]

        # Top-K召回率
        recall = cal_recall(pred, true, self.topK)

        return {
            "mse": mse,
            "pearson": pearson_corr,
            "spearman": spearman_corr,
            f"recall@{self.topK}": recall
        }
```

#### 5.2.2 下游任务类型

根据评估数据集,项目支持以下下游任务:

1. **蛋白质-蛋白质相互作用预测**

   - 任务类型: 二分类或回归
   - 评估指标: AUC, 精确率, 召回率, 相关系数
2. **细胞穿透肽预测**

   - 任务类型: 二分类
   - 评估指标: AUC, 精确率, 召回率
3. **溶解度预测**

   - 任务类型: 回归
   - 评估指标: MSE, 皮尔逊相关系数, 斯皮尔曼相关系数
4. **可合成性预测**

   - 任务类型: 二分类
   - 评估指标: AUC, 精确率, 召回率

### 5.3 基线模型对比

根据论文描述,PepLand与以下基线模型进行对比:

1. **ESM (Evolutionary Scale Modeling)**

   - Meta开发的蛋白质语言模型
   - 基于Transformer架构
2. **ProteinBERT**

   - 蛋白质序列的BERT变体
   - 仅支持标准氨基酸
3. **小分子模型**

   - ChemBERTa: 化学分子的BERT变体
   - GIN: 图同构网络
   - GCN: 图卷积网络

**对比维度**:

- 预测性能 (各下游任务的评估指标)
- 泛化能力 (标准氨基酸 vs 非标准氨基酸)
- 训练效率 (参数量、训练时间)
- 可解释性 (注意力可视化、片段重要性)

---

## 六、代码完整性评估

### 6.1 核心功能完整性

#### 6.1.1 ✅ 数据处理模块

**文件**: `model/data.py`, `tokenizer/pep2fragments.py`

**完整功能**:

- ✅ SMILES到异构图转换 (`Mol2HeteroGraph`)
- ✅ 分子片段化 (AdaFrag算法)
- ✅ 多视图特征提取 (原子、片段、键)
- ✅ 掩码策略实现 (`MaskAtom`)
- ✅ 数据加载器 (`MolGraphSet`, `make_loaders`)

**缺失功能**:

- ❌ 数据增强策略文档
- ❌ 异常SMILES处理的详细日志

#### 6.1.2 ✅ 模型定义模块

**文件**: `model/model.py`, `model/hgt.py`, `model/core.py`

**完整功能**:

- ✅ PharmHGT主模型 (`class PharmHGT`)
- ✅ 多视图消息传递 (`class MVMP`)
- ✅ 注意力机制 (`class MultiHeadedAttention`)
- ✅ 图读出层 (`class Node_GRU`)
- ✅ 特征提取器 (`class PepLandFeatureExtractor`)
- ✅ 性质预测器 (`class PropertyPredictor`)

**可选模型**:

- ✅ HGT (Heterogeneous Graph Transformer)
- ✅ HeteroRGCN

#### 6.1.3 ✅ 训练模块

**文件**: `trainer.py`, `pretrain_masking.py`

**完整功能**:

- ✅ 两阶段预训练流程
- ✅ 多任务联合训练 (`Masking_Trainer`)
- ✅ 分布式训练支持 (DDP)
- ✅ 实验跟踪 (MLflow)
- ✅ 模型检查点保存
- ✅ 验证和测试评估

**缺失功能**:

- ⚠️ 学习率调度器 (代码中注释掉)
- ⚠️ Early stopping机制未实现

#### 6.1.4 ✅ 推理模块

**文件**: `inference.py`, `model/core.py`

**完整功能**:

- ✅ 模型加载 (`load_model`)
- ✅ 批量推理支持
- ✅ SMILES输入处理
- ✅ 特征提取接口
- ✅ 缓存机制 (最大100,000条SMILES)

**使用示例**:

```python
model = PepLandFeatureExtractor(model_path, pooling='avg')
with open('input.smi', 'r') as f:
    input_smiles = f.readlines()
pep_embeds = model(input_smiles)
```

#### 6.1.5 ✅ 评估模块

**文件**: `utils/metrics.py`

**完整功能**:

- ✅ 分类任务指标 (`MulticlassMetrics`)
- ✅ 回归任务指标 (`AffinityMetrics`)
- ✅ Top-K召回率计算
- ✅ 相关系数计算 (Pearson, Spearman)

**缺失功能**:

- ❌ 下游任务完整的评估脚本
- ❌ 与基线模型的对比实验代码

#### 6.1.6 ✅ 实用工具

**文件**:

- `utils/utils.py`: 通用工具函数
- `utils/distribution.py`: 分布式训练工具
- `utils/std_logger.py`: 日志记录
- `splitters.py`: 数据划分工具

**完整功能**:

- ✅ 随机种子固定
- ✅ 设备管理
- ✅ 模型加载工具
- ✅ 分布式初始化
- ✅ 数据集划分 (随机、scaffold、时间划分)

### 6.2 配置文件完整性

#### 6.2.1 ✅ 预训练配置

**文件**: `configs/pretrain_masking.yaml`

```yaml
完整包含:
- hydra配置 ✅
- 运行模式 (ddp, nni) ✅
- 训练超参数 ✅
- 模型配置 ✅
- 掩码策略 ✅
- 数据路径 ✅
- 日志配置 ✅
```

#### 6.2.2 ✅ 推理配置

**文件**: `configs/inference.yaml`

```yaml
完整包含:
- 模型路径 ✅
- 设备配置 ✅
- 池化方式 ✅
- 输入数据路径 ✅
```

#### 6.2.3 ⚠️ 下游任务配置

**文件**: `configs/bbbp.json`, `configs/esol.json`, `configs/test.json`

**提供的示例配置**:

- 部分下游任务的配置文件
- 但缺少完整的微调脚本

### 6.3 测试代码完整性

#### 6.3.1 ✅ 单元测试

**文件**: `test/test_load.py`

**测试内容**:

- ✅ 数据加载器大小验证
- ✅ 图结构正确性验证
- ✅ 掩码功能验证

**缺失测试**:

- ❌ 模型前向传播测试
- ❌ 片段化算法测试
- ❌ 特征提取测试

### 6.4 文档完整性

#### 6.4.1 ✅ 项目文档

**文件**: `README.md`

**包含内容**:

- ✅ 项目介绍
- ✅ 安装说明
- ✅ 使用示例 (预训练、推理)
- ✅ 数据格式说明
- ✅ AdaFrag算法示例

**缺失内容**:

- ❌ 完整的API文档
- ❌ 下游任务微调教程
- ❌ 超参数调优指南
- ❌ 性能基准测试结果

#### 6.4.2 ✅ 技术文档

**文件**: `doc/` 目录

**包含资源**:

- ✅ 架构图 (`arch.png`)
- ✅ 片段化示意图 (`fragmentation.png`)
- ✅ 多视图图示 (`multi-view.png`)
- ✅ AdaFrag示例 (`Adafrag.png`)

### 6.5 ⚠️ 缺失的关键组件

#### 6.5.1 ❌ 下游任务微调脚本

**缺失**:

- 完整的微调训练脚本
- 超参数搜索脚本
- 与基线模型的对比实验代码

**影响**:

- 用户难以直接在自己的下游任务上应用模型
- 无法复现论文中的实验结果

#### 6.5.2 ❌ 数据预处理脚本

**缺失**:

- 原始数据收集脚本
- 数据清洗和过滤脚本
- 数据统计和可视化脚本 (部分在 `data/eval/statistics.py`)

**影响**:

- 无法理解数据来源和质量
- 难以扩展到新的数据集

#### 6.5.3 ⚠️ 模型分析工具

**部分缺失**:

- 注意力权重可视化
- 片段重要性分析
- 错误案例分析

**影响**:

- 模型可解释性受限
- 难以进行深入的模型分析

### 6.6 代码质量评估

#### 6.6.1 ✅ 优点

1. **模块化设计**

   - 清晰的模块划分 (data, model, utils, tokenizer)
   - 良好的代码组织结构
2. **配置管理**

   - 使用Hydra进行配置管理
   - 支持命令行参数覆盖
3. **实验跟踪**

   - 集成MLflow进行实验管理
   - 完整的日志记录
4. **分布式训练**

   - 支持多GPU并行训练
   - 使用PyTorch DDP

#### 6.6.2 ⚠️ 待改进之处

1. **代码注释**

   - 部分核心函数缺少详细注释
   - 算法逻辑说明不够充分
2. **错误处理**

   - 缺少完善的异常处理机制
   - 输入验证不够严格
3. **测试覆盖率**

   - 单元测试覆盖率较低
   - 缺少集成测试
4. **代码复用**

   - 部分代码存在冗余 (如 `cpkt/`目录下的重复代码)

---

## 七、总结与建议

### 7.1 项目优势

1. **创新性**

   - ✅ 首个支持非标准氨基酸的肽段表示学习模型
   - ✅ 多视图异构图架构,综合原子和片段信息
   - ✅ 自定义的AdaFrag片段化算法
2. **技术实现**

   - ✅ 完整的预训练流程 (两阶段策略)
   - ✅ 多任务联合训练 (原子、片段、键预测)
   - ✅ 分布式训练支持
3. **数据规模**

   - ✅ 大规模预训练数据集 (约79万条肽段)
   - ✅ 多样化的下游评估数据集
4. **工程质量**

   - ✅ 模块化设计
   - ✅ 配置管理 (Hydra)
   - ✅ 实验跟踪 (MLflow)
   - ✅ 可扩展的推理接口

### 7.2 主要不足

1. **文档不完善**

   - ❌ 缺少完整的API文档
   - ❌ 下游任务微调教程不足
   - ❌ 超参数调优指南缺失
2. **代码缺失**

   - ❌ 下游任务完整微调脚本
   - ❌ 基线模型对比实验代码
   - ❌ 数据预处理脚本
3. **测试不充分**

   - ⚠️ 单元测试覆盖率低
   - ❌ 缺少集成测试
   - ❌ 缺少性能测试
4. **可解释性工具**

   - ⚠️ 注意力可视化未提供
   - ⚠️ 片段重要性分析工具缺失

### 7.3 改进建议

#### 7.3.1 短期改进 (1-2周)

1. **补充文档**

   - 编写完整的API文档
   - 添加下游任务微调教程
   - 提供超参数调优指南
2. **补充代码**

   - 提供下游任务微调脚本模板
   - 添加数据预处理示例脚本
   - 补充错误处理逻辑
3. **增加测试**

   - 编写核心功能的单元测试
   - 添加端到端测试用例

#### 7.3.2 中期改进 (1-3个月)

1. **性能优化**

   - 实现模型量化和压缩
   - 优化推理速度
   - 添加批处理优化
2. **可解释性工具**

   - 实现注意力权重可视化
   - 开发片段重要性分析工具
   - 提供案例分析脚本
3. **功能扩展**

   - 支持更多下游任务
   - 添加数据增强策略
   - 实现主动学习接口

#### 7.3.3 长期改进 (3-6个月)

1. **模型迭代**

   - 探索更大规模的预训练数据
   - 尝试新的架构设计
   - 集成最新的图神经网络技术
2. **生态建设**

   - 发布PyPI包,方便安装使用
   - 建立社区和论坛
   - 提供在线演示和API服务
3. **应用拓展**

   - 开发特定领域的应用 (如药物设计)
   - 与实验平台集成
   - 建立标准化的评估基准

### 7.4 使用建议

#### 7.4.1 对于研究人员

1. **预训练模型使用**

   ```python
   # 加载预训练模型
   model = PepLandFeatureExtractor(
       model_path='path/to/checkpoint',
       pooling='avg',
       freeze=True
   )

   # 提取肽段嵌入
   embeddings = model(['CC(C)...', 'CC[C@H]...'])
   ```
2. **下游任务微调**

   - 使用 `PropertyPredictor` 作为起点
   - 根据具体任务调整MLP结构
   - 尝试不同的池化策略 (`avg`, `max`, `gru`)
3. **实验设置**

   - 使用配置文件管理实验
   - 利用MLflow跟踪实验结果
   - 进行充分的超参数搜索

#### 7.4.2 对于应用开发者

1. **集成建议**

   - 使用推理API进行批量预测
   - 实现缓存机制以加速重复查询
   - 考虑模型量化以降低资源消耗
2. **性能优化**

   - 使用GPU加速推理
   - 实现批处理以提高吞吐量
   - 缓存常用肽段的嵌入
3. **错误处理**

   - 验证输入SMILES的有效性
   - 处理异常情况 (如无法片段化的分子)
   - 提供友好的错误提示

---

## 八、参考资源

### 8.1 论文与文档

- **主论文**: [PepLand: a large-scale pre-trained peptide representation model for a comprehensive landscape of both canonical and non-canonical amino acids](https://arxiv.org/abs/2311.04419)
- **项目README**: `README.md`
- **架构图**: `doc/arch.png`

### 8.2 代码仓库

- **GitHub**: (需要补充项目链接)

### 8.3 依赖包

**核心依赖**:

- PyTorch >= 1.10
- DGL (Deep Graph Library) >= 0.9
- RDKit >= 2022.09
- Hydra >= 1.2
- MLflow
- NumPy, Pandas, scikit-learn

**完整依赖**: 参见 `environment.yaml`

### 8.4 数据资源

- **PepAtlas**: https://www.peptideatlas.org/
- **UniParc**: https://www.uniprot.org/uniparc/
- **评估数据集**: `data/eval/`

---

## 附录

### A. 关键文件列表

```
pepland/
├── model/                   # 模型定义
│   ├── data.py             # 数据处理 ★★★★★
│   ├── model.py            # PharmHGT模型 ★★★★★
│   ├── hgt.py              # HGT变体
│   ├── core.py             # 推理接口 ★★★★
│   └── util.py             # 工具函数
├── tokenizer/              # 分子片段化
│   ├── pep2fragments.py    # AdaFrag算法 ★★★★★
│   └── vocabs/             # 片段词汇表
├── utils/                  # 工具模块
│   ├── metrics.py          # 评估指标 ★★★★
│   ├── utils.py            # 通用工具
│   ├── distribution.py     # 分布式训练
│   └── std_logger.py       # 日志
├── configs/                # 配置文件
│   ├── pretrain_masking.yaml  # 预训练配置 ★★★★
│   ├── inference.yaml      # 推理配置 ★★★
│   └── *.json              # 下游任务配置
├── data/                   # 数据目录
│   ├── pretrained/         # 预训练数据 ★★★★★
│   ├── further_training/   # 微调数据 ★★★★
│   └── eval/               # 评估数据集 ★★★★
├── trainer.py              # 训练循环 ★★★★★
├── pretrain_masking.py     # 预训练入口 ★★★★★
├── inference.py            # 推理脚本 ★★★★
├── splitters.py            # 数据划分
├── test/                   # 测试代码
│   └── test_load.py        # 数据加载测试
└── README.md               # 项目文档 ★★★★

★ 重要性评级 (1-5星)
```

### B. 模型参数统计

**PharmHGT模型**:

- **参数量**: 约 5-10M (取决于配置)
  - 特征投影层: ~0.5M
  - 消息传递层: ~4M (5层)
  - 预测头: ~0.5M
- **隐藏维度**: 300
- **消息传递层数**: 5
- **注意力头数**: 4
- **总训练时间** (估计):
  - 第一阶段 (标准氨基酸): ~2-3天 (8 x V100 GPU)
  - 第二阶段 (非标准氨基酸): ~1天

### C. 性能基准 (根据论文)

**下游任务性能** (相对于基线提升):

| 任务             | 数据集    | 性能提升          |
| ---------------- | --------- | ----------------- |
| 蛋白质结合       | c-binding | +5-10% AUC        |
| 细胞穿透         | c-CPP     | +3-8% AUC         |
| 溶解度           | c-Sol     | +0.1-0.15 Pearson |
| 非标准氨基酸任务 | nc-*      | 显著优于基线      |

**推理性能**:

- 单条肽段嵌入提取: ~10-50ms (GPU)
- 批处理 (batch_size=32): ~100-200ms (GPU)
- 内存占用: ~2-4GB (GPU)

### D. 常见问题 (FAQ)

#### Q1: 如何处理超长肽段序列?

**A**: 模型基于图神经网络,理论上可以处理任意长度的序列。但实际应用中建议:

- 长度 <100个氨基酸: 直接处理
- 长度 100-200: 考虑增大batch size
- 长度 >200: 考虑分段处理或使用滑动窗口

#### Q2: 如何提高推理速度?

**A**:

1. 使用批处理 (batch inference)
2. 启用SMILES缓存机制
3. 考虑模型量化 (int8/fp16)
4. 使用GPU加速

#### Q3: 模型是否支持修饰氨基酸?

**A**: 是的,只要能表示为SMILES,模型就能处理。第二阶段训练专门针对非标准氨基酸。

#### Q4: 如何在自己的数据集上微调?

**A**:

1. 准备数据: 转换为CSV格式,包含 `smiles`和标签列
2. 创建PropertyPredictor实例
3. 定义损失函数和优化器
4. 训练并评估

#### Q5: 预训练模型的局限性?

**A**:

- 不支持环肽的特殊处理
- 对极长序列 (>500个氨基酸) 性能下降
- 不直接支持3D结构信息

---

**报告编写日期**: 2025-10-13
**报告版本**: v1.0
**作者**: AI技术调研组