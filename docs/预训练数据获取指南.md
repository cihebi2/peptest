# 预训练数据获取指南

## 概述

本指南介绍如何使用 `预训练数据抓住脚本.py` 从 UniProt 等数据源获取肽段序列数据,用于模型的预训练。

**脚本位置**: `pepland/data/预训练数据抓住脚本.py`

## 主要功能

### Stage 1: 基础序列获取

#### 1.1 获取已审核的短序列

从 UniProtKB/Swiss-Prot 获取指定长度范围内的已审核序列。

```bash
python 预训练数据抓住脚本.py stage1-fetch-reviewed \
    --min_len 5 \
    --max_len 50 \
    --out output.fasta
```

**参数说明**:
- `--min_len`: 最小序列长度 (默认: 5)
- `--max_len`: 最大序列长度 (默认: 50)
- `--out`: 输出 FASTA 文件路径

**注意**: 此方法获取的是完整的蛋白质条目序列,可能会遗漏嵌入在前体蛋白中的成熟肽段。

#### 1.2 提取成熟肽段特征 (推荐)

从 Swiss-Prot 条目中提取 FEATURE 字段标注的成熟肽段 (PEPTIDE/PROPEP/CHAIN)。

```bash
python 预训练数据抓住脚本.py stage1-extract-features \
    --min_len 5 \
    --max_len 50 \
    --max_entries 1000 \
    --out mature_peptides.fasta
```

**参数说明**:
- `--min_len`: 最小肽段长度 (默认: 5)
- `--max_len`: 最大肽段长度 (默认: 50)
- `--max_entries`: 最大处理条目数 (默认: None,处理所有条目)
- `--out`: 输出 FASTA 文件路径

**优势**:
- 不会遗漏前体蛋白中的成熟肽段
- 提取的序列包含完整序列和特征肽段
- 支持限制处理条目数,便于快速测试

**输出格式**:
```
>P12345|FULL|1-45
ACDEFGHIKLMNPQRSTVWY...
>P12345|PEPTIDE|10-25|Antimicrobial peptide
GHIKLMNPQRSTV
```

#### 1.3 合并、清理和去重

合并多个数据源,过滤非标准氨基酸,并进行序列去重。

```bash
python 预训练数据抓住脚本.py stage1-merge-clean \
    --inputs file1.fasta file2.fasta file3.fasta \
    --out merged.fasta \
    --dedupe uniref90
```

**参数说明**:
- `--inputs`: 输入的 FASTA 文件列表 (空格分隔)
- `--out`: 输出 FASTA 文件路径
- `--dedupe`: 去重策略
  - `none`: 仅精确序列去重
  - `uniref100`: UniRef100 聚类去重 (100% 序列一致性)
  - `uniref90`: UniRef90 聚类去重 (90% 序列一致性,推荐)
  - `uniref50`: UniRef50 聚类去重 (50% 序列一致性)
  - `cdhit`: 标记需要使用 CD-HIT 工具

**去重流程**:
1. 过滤非标准氨基酸序列 (只保留 20 种标准氨基酸)
2. 精确序列去重
3. (可选) 基于 UniRef 聚类的去重

### Stage 2: 非经典/环肽数据 (占位符)

查看非经典氨基酸和环肽数据源的集成计划:

```bash
python 预训练数据抓住脚本.py stage2-placeholder
```

**计划的数据源**:
- **CycPeptMPDB**: 环肽膜透过性数据库
- **PDB + CCD + SIFTS**: 从蛋白质结构数据库提取非经典氨基酸

### 下游任务数据集构建 (占位符)

#### 细胞穿透肽 (CPP)

```bash
python 预训练数据抓住脚本.py cpp-build
```

**数据源**:
- CPPsite 2.0: 正样本
- CycPeptMPDB: 渗透性数值
- Stage-1 数据: 负样本 (经过相似性过滤)

#### 溶解度预测

```bash
python 预训练数据抓住脚本.py solubility-build
```

**数据源**:
- PROSO-II (长度 < 50 aa)
- APD/DRAMP/DBAASP/dbAMP (溶解度注释)

#### 肽-蛋白亲和力

```bash
python 预训练数据抓住脚本.py affinity-build
```

**数据源**:
- PepBDB/Propedia/PepBind: 结构信息
- PEPBI (2025): 高质量热力学数据

### 数据集统计报告

生成数据集的统计信息,包括序列数量、长度分布等。

```bash
python 预训练数据抓住脚本.py report \
    --inputs file1.fasta file2.fasta file3.fasta \
    --out report.json
```

**输出示例**:
```json
{
  "swissprot_5-50aa.fasta": {
    "n_sequences": 12345,
    "length_min": 5,
    "length_max": 50,
    "length_mean": 27.3,
    "length_p50": 25,
    "length_p25": 15,
    "length_p75": 38
  }
}
```

## 完整使用示例

### 快速测试 (小数据集)

```bash
# 1. 提取成熟肽段 (测试模式,只处理 100 个条目)
python 预训练数据抓住脚本.py stage1-extract-features \
    --min_len 5 \
    --max_len 50 \
    --max_entries 100 \
    --out test_peptides.fasta

# 2. 生成统计报告
python 预训练数据抓住脚本.py report \
    --inputs test_peptides.fasta \
    --out test_report.json

# 3. 查看结果
cat test_report.json
head -n 20 test_peptides.fasta
```

### 生产环境 (完整数据集)

```bash
# 1. 获取 Swiss-Prot 已审核序列
python 预训练数据抓住脚本.py stage1-fetch-reviewed \
    --min_len 5 \
    --max_len 50 \
    --out swissprot_5-50aa.fasta

# 2. 提取成熟肽段特征 (处理所有条目)
python 预训练数据抓住脚本.py stage1-extract-features \
    --min_len 5 \
    --max_len 50 \
    --out mature_peptides.fasta

# 3. 合并并去重
python 预训练数据抓住脚本.py stage1-merge-clean \
    --inputs swissprot_5-50aa.fasta mature_peptides.fasta \
    --out merged_peptides.fasta \
    --dedupe uniref90

# 4. 生成最终报告
python 预训练数据抓住脚本.py report \
    --inputs swissprot_5-50aa.fasta \
             mature_peptides.fasta \
             merged_peptides.fasta \
    --out final_report.json
```

## 注意事项

### 1. API 速率限制

UniProt REST API 有速率限制,大规模数据获取时:
- 脚本已内置重试机制 (最多 5 次)
- 请求间隔会自动递增
- 建议在非高峰时段运行

### 2. 数据量估算

- Swiss-Prot 5-50 aa 序列: 约 10,000-20,000 条
- 成熟肽段特征: 可能提取更多序列 (包括前体蛋白中的肽段)
- 完整数据获取可能需要数小时

### 3. 进度监控

脚本会实时显示:
- 当前处理的页数/条目数
- 已提取的序列数量
- 错误和警告信息

### 4. 错误处理

- 网络错误: 自动重试,失败后继续处理剩余数据
- 数据解析错误: 记录警告,跳过问题条目
- 前 10 个错误会详细打印,之后的错误静默处理

### 5. 输出文件

所有输出文件为标准 FASTA 格式:
- 每行序列最多 80 个字符
- UTF-8 编码
- 自动创建输出目录

## 依赖项

```bash
pip install requests
```

## 性能优化建议

1. **使用 max_entries 参数**: 先用小数据集测试流程
2. **并行处理**: 可以将数据分批处理,最后合并
3. **本地缓存**: 保存中间结果,避免重复下载
4. **UniRef 去重**: 对于大数据集,UniRef90 是速度和质量的最佳平衡

## 常见问题

### Q1: 为什么推荐使用 stage1-extract-features 而不是 stage1-fetch-reviewed?

A: `stage1-extract-features` 会提取 UniProt 条目中标注的成熟肽段 (PEPTIDE/PROPEP/CHAIN),这些肽段可能嵌入在较长的前体蛋白中,使用 `stage1-fetch-reviewed` 会遗漏这些重要的生物活性肽段。

### Q2: UniRef 去重的原理是什么?

A: UniRef (UniProt Reference Clusters) 将序列按相似度聚类:
- UniRef100: 100% 一致性 (去除完全相同的序列)
- UniRef90: 90% 一致性 (去除高度相似的序列,推荐)
- UniRef50: 50% 一致性 (去除中等相似的序列,数据量更少)

### Q3: 如何处理非标准氨基酸?

A: 当前版本会过滤掉包含非标准氨基酸的序列。Stage-2 计划支持非经典氨基酸和修饰,需要从 CycPeptMPDB 和 PDB CCD 等数据源获取。

### Q4: 可以获取特定物种的数据吗?

A: 当前版本获取所有物种的数据。未来可以通过修改查询条件 (query 参数) 来限制物种,例如:
```python
query.append("organism_id:9606")  # 人类
```

## 下一步

1. 查看 `使用示例.sh` 获取可执行的脚本示例
2. 根据实际需求修改参数
3. 将获取的数据用于模型预训练
4. 记录数据获取过程到 `docs/训练计划.md`

## 更新记录

- 2025-10-15: 完善脚本功能,添加进度显示和错误处理
- 初始版本: 基础骨架脚本
