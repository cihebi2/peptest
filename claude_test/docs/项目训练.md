# PepLand 项目训练策略文档

**文档版本**: v1.0  
**最后更新**: 2025-10-14  
**目的**: 记录完整训练流程、策略调整和结果分析，便于复现和迭代

---

## 数据集概览

### 1. 训练数据集 (data_large/)
- 总样本数: 1067个
- 数据来源: 3个数据源合并 (pepBench, pep2d, pep3d)
- 数据分割: 训练集853 / 验证集107 / 测试集107
- 特征维度: 原子38维 / 键14维 / 片段196维

### 2. 下游任务数据集 (data/eval/)

#### 2.1 结合亲和力预测 (Binding Affinity)
- 文件: c-binding.csv (1807) + nc-binding.csv (305) = 2112样本
- 任务: 回归预测Kd值
- 应用: 药物-靶点结合强度预测

#### 2.2 细胞穿透肽预测 (CPP Classification)
- 文件: nc-CPP.csv (7335样本) - 最大规模数据集
- 任务: 二分类预测穿透性
- 优先级: P0 (样本量大，实用性强)

#### 2.3 溶解度预测 (Solubility)
  - 样本数: 1511个
  - 任务类型: 二分类
  - 标签分布:
    - 不溶解 (0): 634样本 (42%)
    - 可溶解 (1): 877样本 (58%)
  - 数据格式: 氨基酸序列 + 溶解度标签
  - 样本平衡度: 较好 (约4:6)

---

## 模型架构

### ImprovedPepLand 配置
- hidden_dim: 256
- num_layers: 6
- num_heads: 8
- dropout: 0.1
- use_performer: True
- use_virtual_node: True
- 总参数量: ~6.75M

### 架构特点
1. Graphormer - 图结构编码
2. Performer - 高效自注意力
3. Hierarchical Pooling - 多层次图表示
4. Virtual Node - 全局信息聚合

---

## 训练阶段记录

### 阶段1: 监督学习基线 (Supervised Learning)

**目标**: 建立baseline模型，验证架构有效性

**训练配置**:
- 脚本: train_large_supervised.py
- 设备: GPU 2 (CUDA:0)
- 数据: data_large (1067样本)
- 超参数: batch_size=32, lr=1e-4, epochs=20
- 混合精度: FP16 (autocast + GradScaler)

**训练结果**:
- 最佳验证损失: 0.8237 (Epoch 8)
- 测试损失: 0.8821
- 训练时间: ~2分钟
- 状态: ✅ 收敛稳定，FP16正常

---

### 阶段2: 对比学习预训练 (Contrastive Learning)

**目标**: 自监督预训练，学习通用肽段表示

#### 初始尝试 - 失败
- 问题: FP16溢出错误
- 原因: exp(sim_matrix/temperature) 在FP16下溢出
- 具体: exp(50/0.07) = exp(714) >> 65504 (FP16最大值)

#### 调试过程
1. 降低学习率 1e-4 → 5e-5 (部分改善)
2. 增加温度 0.07 → 0.5 (减少溢出)
3. 放宽梯度阈值 10.0 → 50.0 (避免过度跳过)
4. 修复scaler状态错误

#### 最终解决方案 - 禁用混合精度
- 脚本: train_large_contrastive_fixed.py
- 设备: GPU 3 (CUDA:0)
- 关键修改:
  1. 移除FP16/AMP，使用FP32全精度
  2. temperature: 0.5 (数值稳定)
  3. learning_rate: 5e-5
  4. 添加torch.clamp()防止溢出

**数值稳定性措施** (pretraining/contrastive.py):
```python
# 1. 裁剪相似度矩阵 [-1, 1]
sim_matrix = torch.clamp(sim_matrix, min=-1.0, max=1.0)

# 2. 应用温度
sim_matrix = sim_matrix / self.temperature

# 3. 再次裁剪 [-50, 50] 防止exp溢出
sim_matrix = torch.clamp(sim_matrix, min=-50, max=50)

# 4. 使用logsumexp提高数值稳定性
neg_sim = torch.logsumexp(masked_sim, dim=1)
```

**训练结果**:
- 初始损失: 3.7193 (Epoch 1)
- 最终损失: 2.2504 (Epoch 50)
- 损失下降: 39.5%
- 训练时间: ~5.5分钟 (50 epochs)
- 状态: ✅ 无NaN，稳定收敛

#### 经验总结
1. **温度参数影响极大**: 太小(0.07)易溢出，合理值0.1-0.5
2. **FP16需谨慎**: 最大值仅65504，对比学习涉及exp()风险高
3. **损失函数需保护**: 多层裁剪 + logsumexp
4. **梯度阈值要合理**: 太严格(10.0)跳过过多，建议50.0-100.0

---

## 结果对比分析

### 监督学习 vs 对比学习

| 维度 | 监督学习 | 对比学习 |
|------|---------|---------|
| 任务类型 | 回归预测 | 表示学习 |
| 标签需求 | 需要 | 不需要 |
| 损失函数 | MSELoss | InfoNCE |
| 最终损失 | 0.8821 | 2.2504 |
| 训练时长 | 2分钟/20 epochs | 5.5分钟/50 epochs |
| 混合精度 | ✅ FP16正常 | ❌ FP16溢出→FP32 |
| 收敛稳定性 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ (修复后) |

### 不能直接比较的原因
1. 任务目标不同 (拟合标签 vs 学习相似性)
2. 损失函数不同 (MSELoss vs InfoNCE)
3. 评估方式不同 (需通过下游任务验证)

---

## 下游任务评估计划

### 优先级排序

#### P0: CPP分类任务
- 数据: nc-CPP.csv (7335样本)
- 任务: 预测细胞穿透能力
- 指标: Accuracy, AUC-ROC, F1-Score
- 对比: Random vs Pretrained vs Supervised
- GPU: GPU 1 (空闲)

#### P1: 结合亲和力回归
- 数据: c-binding.csv + nc-binding.csv (2112样本)
- 任务: 预测Kd值
- 指标: MSE, MAE, R², Pearson相关系数
- GPU: GPU 2 (空闲)

#### P2: 溶解度预测
- 数据: c-Sol.txt (待确认)

### 实验设计

**标准流程**:
```
for task in [CPP分类, 结合亲和力, 溶解度]:
    for init in [random, pretrained_contrastive, pretrained_supervised]:
        1. 加载编码器 (冻结/微调)
        2. 添加任务头
        3. 训练N epochs
        4. 记录最佳指标
        5. 保存模型和日志
    生成对比报告
```

**学习率设置**:
- 任务头: 1e-3
- 微调编码器: 1e-5
- 端到端训练: 1e-4

---

## 训练脚本清单

### 已完成
- train_large_supervised.py → best_model_large.pt
- train_large_contrastive_fixed.py → best_pretrained_encoder_large_fixed.pt

### 待开发
- downstream_cpp_classification.py (P0)
- downstream_binding_regression.py (P1)
- compare_pretraining_methods.py (P1)
- evaluate_all_downstream.py (P2)

---

## 待解决问题

### 数据相关
- [ ] 确认c-Sol.txt数据格式
- [ ] 检查pretrained/和further_training/内容
- [ ] 验证CPP数据集标签分布
- [ ] 统计SMILES重叠情况

### 模型相关
- [ ] 对比编码器表示质量 (t-SNE可视化)
- [ ] 分析增强策略有效性
- [ ] 测试不同projection_dim影响
- [ ] 验证Virtual Node必要性

### 训练相关
- [ ] 尝试恢复FP16训练
- [ ] 实验更大batch_size (多GPU)
- [ ] 测试其他对比学习框架 (MoCo, SwAV)
- [ ] 添加learning rate warmup

---

## 训练问答记录

**Q1: 为什么只有1067样本，不是80万?**
A: 当前用项目特定数据验证架构，原80万是完整预训练集。策略是先小数据集验证，再扩展。

**Q2: 监督学习和对比学习的目的?**
A: 监督学习建立baseline；对比学习学习通用表示，期望下游任务表现更好。

**Q3: 为什么对比学习问题多?**
A: 对比学习对数值稳定性要求极高，InfoNCE涉及exp()易在FP16溢出。通过调温度、禁用混合精度、裁剪保护解决。

**Q4: 当前空闲GPU?**
A: 空闲 GPU 0,1,2,4,5 / 占用 GPU 3 (86%)

**Q5: GPU编号与CUDA_VISIBLE_DEVICES关系?**
A: CUDA是逻辑编号，通过环境变量映射。如 CUDA_VISIBLE_DEVICES=2 → 物理GPU 2映射为CUDA:0

**Q6: 对比学习和监督学习结果可比较吗?**
A: 不能直接比较。需在相同下游任务上，使用相同指标，对比迁移学习效果。

**Q7: 有哪些下游任务数据?**
A: 结合亲和力2112样本 / CPP分类7335样本(优先) / 溶解度待确认

---

## 技术术语表

| 术语 | 解释 |
|------|------|
| InfoNCE Loss | 对比学习核心损失，最大化正样本相似度，最小化负样本相似度 |
| SimCLR | Simple Framework for Contrastive Learning，谷歌对比学习框架 |
| Temperature (τ) | 温度参数，控制softmax平滑度，τ越小分布越尖锐 |
| Projection Head | 投影头，映射编码器输出到对比学习空间的MLP |
| Data Augmentation | 数据增强，创建同一样本不同视图 |
| FP16/FP32 | 半精度/全精度浮点数，FP16最大65504，FP32最大3.4×10³⁸ |
| Gradient Clipping | 梯度裁剪，防止梯度爆炸 |
| AMP | Automatic Mixed Precision，自动混合精度训练 |
| Virtual Node | 虚拟节点，连接所有图节点聚合全局信息 |
| Performer | 线性复杂度的高效Transformer变体 |
| Kd值 | 解离常数，描述配体受体结合强度，越小结合越强 |
| CPP | Cell-Penetrating Peptides，细胞穿透肽 |

---

## 参考文献

1. SimCLR: Chen et al. "A Simple Framework for Contrastive Learning" (ICML 2020)
2. InfoNCE: van den Oord et al. "Representation Learning with Contrastive Predictive Coding" (2018)
3. Graphormer: Ying et al. "Do Transformers Really Perform Bad for Graph Representation?" (NeurIPS 2021)
4. Performer: Choromanski et al. "Rethinking Attention with Performers" (ICLR 2021)
5. PepLand: 原始论文 (待补充)

---

## 版本历史

- v1.0 (2025-10-14): 初始版本，记录阶段1-2训练和下游数据发现

---

**下一步行动**:
1. 开发CPP分类下游任务脚本
2. 执行预训练方法对比实验
3. 更新文档实验结果

---

## 阶段3: 下游任务评估 - 溶解度预测

**目标**: 对比三种预训练方法在下游任务上的性能

### 任务描述
- **任务类型**: 二分类（预测肽段溶解度）
- **数据集**: c-Sol.txt (1511样本)
- **标签分布**: 不溶解(0)634样本 / 可溶解(1)877样本 (4:6)
- **数据分割**: 训练1208 / 验证151 / 测试152
- **评估指标**: Accuracy, Precision, Recall, F1-Score, AUC-ROC

### 实验设计

#### 三种初始化方法对比

**1. Random Initialization (Baseline)**
- 配置: 随机初始化ImprovedPepLand编码器
- 学习率: 1e-4
- 训练策略: 端到端训练
- 目的: 建立性能下界

**2. Pretrained Contrastive**
- 配置: 加载对比学习预训练权重 (best_pretrained_encoder_large_fixed.pt)
- 学习率: 1e-5 (微调)
- 训练策略: 解冻编码器，低学习率微调
- 目的: 验证自监督预训练效果

**3. Pretrained Supervised**
- 配置: 加载监督学习预训练权重 (best_model_large.pt)
- 学习率: 1e-5 (微调)
- 训练策略: 解冻编码器，低学习率微调
- 目的: 验证监督预训练迁移能力

#### 训练配置
```python
配置:
- batch_size: 32
- num_epochs: 30
- optimizer: Adam
- scheduler: ReduceLROnPlateau (mode='max', factor=0.5, patience=3)
- criterion: CrossEntropyLoss
- gradient_clipping: 1.0
- task_head: Linear(256→128) + ReLU + Dropout(0.2) + Linear(128→2)
```

#### 数据处理
由于数据格式为氨基酸序列而非SMILES，采用简化处理：
1. 将每个氨基酸视为一个节点
2. 使用one-hot编码表示20种氨基酸
3. 肽键连接形成线性图结构
4. Padding到42维以匹配模型输入

### 脚本实现
- **脚本名**: downstream_solubility.py
- **设备**: GPU 1 (CUDA_VISIBLE_DEVICES=1)
- **日志**: test_results/solubility_downstream.log
- **输出**: test_results/solubility_comparison.json

### 实验执行
```bash
# 启动实验
CUDA_VISIBLE_DEVICES=1 python downstream_solubility.py > test_results/solubility_downstream.log 2>&1 &

# 监控进度
tail -f test_results/solubility_downstream.log
```

### 预期结果对比

| 初始化方法 | 预期效果 | 假设 |
|-----------|---------|------|
| Random | Baseline性能 | 从头学习，可能过拟合 |
| Contrastive | 更好泛化 | 学到通用表示，有助迁移 |
| Supervised | 中等性能 | 预训练任务与下游任务差异较大 |

### 评估流程
1. 对每种初始化方法：
   - 加载编码器权重（如适用）
   - 添加任务头（2层MLP）
   - 训练30 epochs
   - 记录最佳验证准确率
   - 在测试集上评估
2. 生成对比报告（JSON格式）
3. 分析结果，更新文档

---

**实验状态**: ⏳ 进行中 (2025-10-14)
**预计完成时间**: ~30-45分钟 (3个实验 × 30 epochs)

