# 训练计划与说明 / Training Plan

**文档创建**: 2025-10-14
**项目**: ImprovedPepLand - 肽段表示学习增强版

---

## 📋 项目概述

本项目在 `claude_test` 目录中实现了改进的 PepLand 模型架构，基于论文方案集成了多项先进技术：

### 核心技术栈

1. **Graphormer** (NeurIPS 2021)
   - 中心性编码：度数编码
   - 空间编码：最短路径距离
   - 边特征集成

2. **Performer Attention** (ICLR 2021)
   - FAVOR+ 核方法
   - 线性复杂度 O(n) vs O(n²)
   - 随机特征映射

3. **层次化池化**
   - 全局注意力池化
   - Set Transformer
   - 多尺度表示融合

4. **对比学习**
   - SimCLR 框架
   - MoCo (Momentum Contrast)
   - 图数据增强策略

---

## 🗂️ 数据说明

### 真实数据来源

- **位置**: `/home/qlyu/AA_peptide/pepland/data/pretrained/`
- **格式**: CSV文件，包含 SMILES 字符串
- **规模**:
  - 训练集: 998 样本
  - 验证集: 998 样本
  - 测试集: 998 样本

### 数据加载

- **脚本**: `data_loader_real.py`
- **特征提取**:
  - 原子特征: 38维 (原子类型、度数、电荷、手性、氢原子数、杂化、芳香性、质量)
  - 键特征: 14维 (键类型、共轭、环、立体化学)
- **图构建**: DGL异构图，双向边

---

## 🎯 已完成训练

### 阶段 1: 小规模监督学习 ✅

**日期**: 2025-10-14
**脚本**: `train_real_supervised.py`
**设备**: CUDA 2 (物理GPU 3)
**数据**: 998样本

#### 配置
```yaml
模型: ImprovedPepLand
参数量: 6,651,663 (6.65M)
隐藏维度: 256
层数: 6
注意力头数: 8
批大小: 32
学习率: 1e-4
权重衰减: 1e-5
Dropout: 0.1
Epochs: 10
```

#### 结果
```
最佳验证损失: 0.8983 (Epoch 7)
测试损失: 0.8936
训练时间: ~60秒
每epoch速度: ~5-6秒 (~8 it/s)
模型保存: test_results/best_model_real.pt
```

#### 训练曲线
```
Epoch 1:  Train=1.0817, Val=1.0695
Epoch 2:  Train=1.0025, Val=0.9804 ✓
Epoch 5:  Train=1.0426, Val=0.9504 ✓
Epoch 7:  Train=1.0796, Val=0.8983 ✓ (最佳)
Epoch 10: Train=0.9677, Val=1.0157
```

**结论**:
- ✓ 模型收敛正常
- ✓ 泛化能力良好（测试性能优于验证集）
- ✓ 无过拟合现象

---

### 阶段 2: 对比学习预训练 ⚠️

**日期**: 2025-10-14
**脚本**: `train_real_contrastive.py`
**设备**: CUDA 2 (物理GPU 2)

#### 配置
```yaml
编码器: ImprovedPepLand
参数量: 6,750,863 (6.75M)
投影维度: 128
温度: 0.07
批大小: 32
学习率: 1e-4
Epochs: 50
数据增强: Feature masking + Attribute noise
```

#### 结果
```
Epoch 1: Loss=3.2605 ✓
Epoch 2: Loss=1.3326 ✓
Epoch 3-50: Loss=nan ⚠️
```

**问题**: 从第3个epoch开始出现数值不稳定（NaN损失）

**原因分析**:
1. 学习率可能过大导致梯度爆炸
2. 对比学习温度参数设置不当
3. 数据增强可能产生了异常值
4. 混合精度训练的数值稳定性问题

**状态**: ⚠️ 需要调整超参数重新训练

---

### 阶段 3: 大规模监督学习 ✅

**日期**: 2025-10-14
**脚本**: `train_large_supervised.py`
**设备**: CUDA 2 (物理GPU 3)
**数据**: 1067样本（合并去重后）

#### 数据准备
使用 `prepare_large_dataset.py` 合并了3个数据源：
- pretrained/ (2994样本)
- further_training/ (100样本)
- eval/ (107样本)
- **去重后**: 1067有效SMILES
- **划分**: 853训练 / 107验证 / 107测试

#### 配置
```yaml
模型: ImprovedPepLand
参数量: 6,651,663 (6.65M)
隐藏维度: 256
层数: 6
批大小: 32
学习率: 1e-4
Epochs: 20
```

#### 结果
```
最佳验证损失: 0.8237 (Epoch 8)
测试损失: 0.8821
早停: Epoch 13 (5轮无改进)
模型保存: test_results/best_model_large.pt
```

**结论**:
- ✓ 相比小规模训练略有改进 (0.8936 → 0.8821)
- ✓ 训练稳定，无过拟合
- ✓ 数据质量良好

---

### 阶段 4: 大规模对比学习（修复版）✅

**日期**: 2025-10-14
**脚本**: `train_large_contrastive_fixed.py`
**设备**: CUDA 2 (物理GPU 3)
**数据**: 1067样本

#### 问题排查与修复历程

**问题1**: NaN损失（学习率过高）
- 现象: Epoch 3后损失NaN
- 修复: 学习率 1e-4 → 5e-5, 温度 0.07 → 0.1
- 结果: 前5个epoch正常，但Epoch 6-8出现大量NaN

**问题2**: 梯度异常
- 现象: 所有批次梯度norm 25-37被跳过，Loss=0
- 修复: 梯度阈值 10.0 → 50.0, 裁剪 0.5 → 1.0
- 结果: 部分批次通过，但出现新问题

**问题3**: FP16溢出（最终问题）
- 现象: "value cannot be converted to type at::Half without overflow"
- 原因: 相似度矩阵/温度后exp()超出FP16范围（max=65504）
- 修复方案:
  1. ✅ 对比损失添加数值裁剪 (sim_matrix: [-50, 50])
  2. ✅ 温度 0.1 → 0.5
  3. ✅ **禁用AMP混合精度，使用FP32**

#### 最终配置
```yaml
编码器: ImprovedPepLand
参数量: 6,750,863 (6.75M)
投影维度: 128
温度: 0.5 (数值稳定)
批大小: 32
学习率: 5e-5
精度: FP32 (不使用AMP)
Epochs: 50
梯度裁剪: 1.0
```

#### 结果（训练中）
```
Epoch 1: Loss=3.7193 ✓
Epoch 2: Loss=3.0690 ✓
Epoch 3: Loss=2.7924 ✓
Epoch 4: Loss=2.6867 ✓
Epoch 5: Loss=2.5927 ✓
Epoch 6: Loss=2.5338 ✓
Epoch 7: Loss=2.5057 ✓
速度: ~4 it/s, ~7秒/epoch
状态: 正在运行，损失持续下降
```

**修复要点**:
- ✓ 无NaN、无溢出、无异常跳过
- ✓ 损失稳定下降
- ✓ FP32保证数值稳定性

---

## 📝 下一步训练计划

### 计划 1: 修复对比学习训练 ⏳

**优先级**: 🔴 高

**问题**: 对比学习出现 NaN 损失

**解决方案**:
1. **降低学习率**: 1e-4 → 5e-5 或 1e-5
2. **调整温度**: 0.07 → 0.1 (更保守)
3. **添加梯度裁剪**: `clip_grad_norm_(model.parameters(), 0.5)`
4. **增加数值稳定性**:
   - 使用 `torch.clamp()` 限制logits范围
   - 在损失计算中添加epsilon
5. **调试数据增强**: 检查增强后的图是否包含NaN

**预期效果**: 稳定训练50个epoch，损失持续下降

---

### 计划 2: 使用预训练编码器微调 ⏳

**前置条件**: 完成对比学习预训练

**目标**: 在预训练编码器基础上进行下游任务微调

**步骤**:
1. 加载预训练编码器权重
2. 冻结部分层（可选）
3. 添加任务特定的头
4. 在标注数据上微调
5. 对比有/无预训练的性能差异

**预期提升**: 10-20% 性能改进（基于文献）

---

### 计划 3: 大规模预训练 ⏳

**前置条件**: 验证小规模训练效果

**数据规模**: 使用完整数据集（如可用）

**配置**:
```yaml
Epochs: 100-200
批大小: 64-128
模型: 更大版本 (hidden_dim=512, layers=12)
数据: 10K+ 分子
```

**预期时间**: 数小时到数天

---

### 计划 4: 下游任务评估 ⏳

**任务列表**:
1. **分子性质预测**
   - 溶解度、logP、毒性等

2. **肽段-靶标结合预测**
   - CPP (Cell-Penetrating Peptides)
   - 抗菌肽活性

3. **序列生成**
   - 条件生成
   - 从头设计

**评估指标**:
- 回归: RMSE, MAE, R²
- 分类: AUROC, AUPRC, F1
- 生成: 有效性、多样性、新颖性

---

### 计划 5: 消融实验 ⏳

**目标**: 验证各模块的贡献

**实验组**:
1. Baseline (原始GCN)
2. +Graphormer
3. +Performer
4. +层次化池化
5. +对比学习预训练
6. Full model (所有组件)

**预期**: 量化每个改进的性能增益

---

### 计划 6: 超参数优化 ⏳

**方法**:
- 网格搜索 / 随机搜索
- 贝叶斯优化 (Optuna)

**搜索空间**:
```python
{
    'hidden_dim': [128, 256, 512],
    'num_layers': [4, 6, 8, 12],
    'num_heads': [4, 8, 16],
    'dropout': [0.0, 0.1, 0.2],
    'learning_rate': [1e-5, 5e-5, 1e-4, 5e-4],
    'temperature': [0.05, 0.07, 0.1, 0.2],  # 对比学习
}
```

---

## 🔧 训练脚本说明

### 监督学习
```bash
# 基本训练
CUDA_VISIBLE_DEVICES=2 python train_real_supervised.py

# 自定义配置（需修改脚本）
# 修改 config 字典中的参数
```

### 对比学习
```bash
# 基本预训练
CUDA_VISIBLE_DEVICES=2 python train_real_contrastive.py

# 调试模式（少量数据）
# 在脚本中设置 max_samples=100
```

### 数据加载测试
```bash
# 测试数据加载器
CUDA_VISIBLE_DEVICES=2 python data_loader_real.py
```

---

## 📊 模型架构细节

### ImprovedPepLand 结构

```
输入: 分子图 (原子、键)
  ↓
[Graphormer Encoder]
  - 度数编码 (in/out degree)
  - 空间编码 (最短路径)
  - Performer 注意力 (可选)
  - 6层 × 8头
  ↓
[层次化池化]
  - 全局注意力池化
  - Set Transformer 池化
  - 平均池化
  - 拼接融合
  ↓
输出: 图表示向量 (256维)
```

### 对比学习框架

```
输入图 → [数据增强] → View1, View2
                         ↓
              [共享编码器 (Graphormer)]
                         ↓
              [投影头 (MLP: 256→128)]
                         ↓
              [对比损失 (InfoNCE)]
                         ↓
              最小化同一图不同视图的距离
              最大化不同图的距离
```

---

## 💾 已保存模型

### 监督学习模型
```
test_results/best_model_real.pt (已完成)
  - model_state_dict: 编码器权重
  - task_head_state_dict: 任务头权重
  - config: 训练配置
  - val_loss: 0.8983
  - test_loss: 0.8936
```

### 对比学习模型
```
test_results/best_pretrained_encoder_real.pt (待重训练)
  - encoder_state_dict: 编码器权重
  - model_state_dict: 完整模型权重
  - loss: NaN (需修复)
```

---

## 🐛 已知问题与解决方案

### 问题 1: 对比学习 NaN 损失 ⚠️

**现象**: 第3个epoch后损失变为NaN

**临时解决方案**:
1. 使用已训练的监督学习模型
2. 等待对比学习修复后再做预训练

**永久解决方案**: 见"计划 1"

---

### 问题 2: 训练速度

**现象**: 对比学习比监督学习慢 (~4 vs 8 it/s)

**原因**: 需要两个数据增强视图，计算量翻倍

**优化方案**:
1. 使用更高效的数据增强
2. 增大批大小（如GPU内存允许）
3. 使用多GPU训练

---

## 📈 性能基准

### 当前结果
| 模式 | 测试损失 | 训练时间 | 状态 |
|------|---------|---------|------|
| 监督学习 | 0.8936 | ~60秒 | ✅ |
| 对比学习 | NaN | - | ⚠️ |

### 目标性能
| 任务 | 指标 | 目标 | 当前 |
|------|------|------|------|
| 属性预测 | R² | >0.8 | - |
| 结合预测 | AUROC | >0.85 | - |
| 生成 | 有效率 | >95% | - |

---

## 🔄 训练工作流

### 标准流程

```
1. 数据准备
   ├─ 加载 SMILES
   ├─ 构建分子图
   └─ 特征提取

2. 预训练 (可选)
   ├─ 对比学习
   └─ 保存编码器

3. 监督训练
   ├─ 加载预训练权重 (可选)
   ├─ 添加任务头
   └─ 微调

4. 评估
   ├─ 验证集调参
   ├─ 测试集最终评估
   └─ 下游任务验证

5. 部署
   └─ 模型导出
```

---

## 📚 参考文档

### 项目文档
- `README.md` - 项目整体说明
- `docs/IMPROVEMENT_STRATEGIES.md` - 改进方案详细说明
- `docs/工作总结.md` - 之前工作记录
- `FINAL_STATUS.md` - 最终状态总结

### 代码文件
- `models/improved_pepland.py` - 主模型实现
- `models/graphormer.py` - Graphormer层
- `models/performer.py` - Performer注意力
- `models/hierarchical_pool.py` - 层次化池化
- `pretraining/contrastive.py` - 对比学习
- `pretraining/augmentation.py` - 数据增强

---

## 🎯 里程碑

- [x] **M1**: 完成代码架构实现 (2025-10-14)
- [x] **M2**: 验证模型可训练 (2025-10-14)
- [x] **M3**: 完成小规模监督学习 (2025-10-14)
- [x] **M3.5**: 完成大规模监督学习 (2025-10-14)
- [x] **M4**: 修复对比学习问题 (2025-10-14)
- [ ] **M4.5**: 完成对比学习预训练 (训练中)
- [ ] **M5**: 下游任务评估
- [ ] **M6**: 论文撰写

---

## 💬 训练问答记录

### Q1: 为什么训练样本只有1067个，而不是原PepLand的80万？
**A**: 当前使用的是项目特定的真实肽段数据（data_large目录），来自3个子目录合并去重后的结果。这是用于**测试新架构可行性**的初步训练，不是完整训练。后续可整合PubChem等公开数据集扩大规模。

### Q2: 监督学习和对比学习的目的是什么？
**A**:
- **监督学习**：训练基础模型，验证ImprovedPepLand架构在真实数据上能正常工作，建立性能基线
- **对比学习**：通过自监督预训练学习更好的分子表示，使编码器捕获分子结构内在特征，用于下游任务微调，预期提升泛化能力

### Q3: 为什么对比学习出现这么多问题？
**A**: 对比学习对数值稳定性要求极高，主要问题：
1. **温度参数敏感**：过低导致exp溢出
2. **FP16精度不足**：相似度计算需要高精度
3. **梯度尺度大**：对比损失初期梯度较大

**解决方案**: 降低学习率 + 提高温度 + 使用FP32

### Q4: 当前空闲GPU有哪些？
**A** (2025-10-14检查):
- 空闲: GPU 0, 1, 2, 4, 5
- 占用: GPU 3 (86%利用率)
- GPU 2正在运行对比学习训练

### Q5: GPU编号与CUDA_VISIBLE_DEVICES关系？
**A**: CUDA设备号是**逻辑编号**，由环境变量映射：
- `CUDA_VISIBLE_DEVICES=2` → 物理GPU 2 映射为逻辑CUDA 0
- 代码中使用 `cuda:0` 实际访问物理GPU 2

---

## 📞 联系信息

**项目位置**: `/home/qlyu/AA_peptide/pepland/claude_test/`
**训练日志**: `*.log` 文件
**模型保存**: `test_results/` 目录

---

**最后更新**: 2025-10-14 16:00
**文档版本**: 2.0
**更新内容**: 新增大规模训练结果、对比学习修复过程、问答记录
